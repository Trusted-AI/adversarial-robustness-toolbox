{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc895cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import os, sys\n",
    "from os.path import abspath\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import keras.backend as k\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Activation, Dropout\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "from art.estimators.classification import KerasClassifier\n",
    "from art.attacks.poisoning import PoisoningAttackBackdoor, PoisoningAttackCleanLabelBackdoor\n",
    "from art.attacks.poisoning.perturbations import add_pattern_bd\n",
    "from art.utils import load_mnist, preprocess, to_categorical\n",
    "from art.defences.trainer import AdversarialTrainerMadryPGD\n",
    "\n",
    "\n",
    "from art.estimators.classification.deep_partition_ensemble import DeepPartitionEnsemble"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1816da6f",
   "metadata": {},
   "source": [
    "# Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdd77e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_raw, y_raw), (x_raw_test, y_raw_test), min_, max_ = load_mnist(raw=True)\n",
    "\n",
    "# Random Selection:\n",
    "n_train = np.shape(x_raw)[0]\n",
    "num_selection = 10000\n",
    "random_selection_indices = np.random.choice(n_train, num_selection)\n",
    "x_raw = x_raw[random_selection_indices]\n",
    "y_raw = y_raw[random_selection_indices]\n",
    "\n",
    "# Poison training data\n",
    "percent_poison = .33\n",
    "x_train, y_train = preprocess(x_raw, y_raw)\n",
    "x_train = np.expand_dims(x_train, axis=3)\n",
    "\n",
    "x_test, y_test = preprocess(x_raw_test, y_raw_test)\n",
    "x_test = np.expand_dims(x_test, axis=3)\n",
    "\n",
    "# Shuffle training data\n",
    "n_train = np.shape(y_train)[0]\n",
    "shuffled_indices = np.arange(n_train)\n",
    "np.random.shuffle(shuffled_indices)\n",
    "x_train = x_train[shuffled_indices]\n",
    "y_train = y_train[shuffled_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1eb1c0",
   "metadata": {},
   "source": [
    "# Initialize the Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c0c7c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Keras convolutional neural network - basic architecture from Keras examples\n",
    "# Source here: https://github.com/keras-team/keras/blob/master/examples/mnist_cnn.py\n",
    "def create_model():    \n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=x_train.shape[1:]))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6b105a",
   "metadata": {},
   "source": [
    "# Set up the Model Backdoor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43b4b127",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f8a72bb8bb0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Z1A+gAAAACXBIWXMAAAsTAAALEwEAmpwYAAANoElEQVR4nO3df6zddX3H8dfL/sJeYFKwtZZKFdFYndTlCppuSw1DAUOKUTaajLCEWbJBAovZRliMJFscIyJh05lU6awEYSoQiHZq07gRMla5kFIKZSuyDmvveoG6tQjctvS9P+6X5QL3fO7lfL/nfA99Px/JzTnn+z7f833n2/vq99zz+X7PxxEhAEe/N7XdAID+IOxAEoQdSIKwA0kQdiCJ2f3c2FzPi2M01M9NAqm8qF/pYIx7qlqtsNs+R9JNkmZJ+kZEXFd6/jEa0pk+q84mARRsic0da12/jbc9S9JXJZ0rabmkNbaXd/t6AHqrzt/sZ0h6IiKejIiDkm6XtLqZtgA0rU7Yl0j6+aTHu6tlr2B7re0R2yOHNF5jcwDqqBP2qT4EeM25txGxLiKGI2J4jubV2ByAOuqEfbekpZMenyxpT712APRKnbA/IOk02++0PVfSRZLuaaYtAE3reugtIg7bvkLSjzQx9LY+Ih5trDMAjao1zh4RGyVtbKgXAD3E6bJAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJGpN2Wx7l6QDkl6SdDgihptoCkDzaoW98rGIeKaB1wHQQ7yNB5KoG/aQ9GPbD9peO9UTbK+1PWJ75JDGa24OQLfqvo1fGRF7bC+UtMn24xFx7+QnRMQ6Sesk6XgviJrbA9ClWkf2iNhT3Y5JukvSGU00BaB5XYfd9pDt416+L+njkrY31RiAZtV5G79I0l22X36db0fEDxvpCkDjug57RDwp6fQGewHQQwy9AUkQdiAJwg4kQdiBJAg7kEQTF8Kk8OxnP9qx9o6Lnyiu+/jYomL94PicYn3JbeX6/N3Pdawd2fpYcV3kwZEdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5JgnH2G/uxPv92x9umhX5ZXPrXmxleVy7sOP9+xdtPTH6u58Teun46d0rE2dMOvFdedvfnBpttpHUd2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUjCEf2bpOV4L4gzfVbfttekX33mzI61Zz5Y/j/zhB3lffzL97lYn/vB/ynWr//AnR1rZ7/5heK6P3j+2GL9k/M7Xytf1wtxsFjfMj5UrK865lDX2373Dy4r1t+z9oGuX7tNW2Kz9se+KX+hOLIDSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBJczz5DQ9/bUqjVe+3j662uv3vbqo61v1q5rLztfyl/5/31q97dRUczM/uFI8X60LbRYv3Ee+8o1n99bufv25+/q/xd/EejaY/sttfbHrO9fdKyBbY32d5Z3Z7Q2zYB1DWTt/HflHTOq5ZdLWlzRJwmaXP1GMAAmzbsEXGvpH2vWrxa0obq/gZJFzTbFoCmdfsB3aKIGJWk6nZhpyfaXmt7xPbIIY13uTkAdfX80/iIWBcRwxExPEfzer05AB10G/a9thdLUnU71lxLAHqh27DfI+mS6v4lku5uph0AvTLtOLvt2zTxzeUn2d4t6QuSrpP0HduXSnpK0oW9bBJlh/97b8fa0B2da5L00jSvPfS9Z7voqBl7//Cjxfr755Z/fb+0770da8v+4cniuoeL1TemacMeEWs6lN6Y30IBJMXpskAShB1IgrADSRB2IAnCDiTBJa5ozexTlhbrX7nmK8X6HM8q1r970+90rJ04en9x3aMRR3YgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIJxdrTm8T9ZUqx/eF55KutHD5ano17w2POvu6ejGUd2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCcXb01PgnP9yx9tBnbpxm7fIMQn905ZXF+pv/9afTvH4uHNmBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnG2dFTT53b+XhyrMvj6Gv+8+xiff4PHy7Wo1jNZ9oju+31tsdsb5+07Frbv7C9tfo5r7dtAqhrJm/jvynpnCmW3xgRK6qfjc22BaBp04Y9Iu6VtK8PvQDooTof0F1he1v1Nv+ETk+yvdb2iO2RQxqvsTkAdXQb9q9JOlXSCkmjkm7o9MSIWBcRwxExPGeaCxsA9E5XYY+IvRHxUkQckfR1SWc02xaApnUVdtuLJz38lKTtnZ4LYDBMO85u+zZJqySdZHu3pC9IWmV7hSaGMndJuqx3LWKQvem444r1i3/rvo61/UdeLK479sV3Fevzxh8o1vFK04Y9ItZMsfjmHvQCoIc4XRZIgrADSRB2IAnCDiRB2IEkuMQVtey89v3F+vdP+vuOtdU7P11cd95GhtaaxJEdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5JgnB1F//v7HynWt/3e3xbrPzt8qGPtub85ubjuPI0W63h9OLIDSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKMsyc3e8nbi/WrPv+Pxfo8l3+FLnr44o61t/4T16v3E0d2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCcfajnGeX/4lP//7uYv3CY58t1m89sLBYX/T5zseTI8U10bRpj+y2l9r+ie0dth+1fWW1fIHtTbZ3Vrcn9L5dAN2aydv4w5I+FxHvk/QRSZfbXi7pakmbI+I0SZurxwAG1LRhj4jRiHioun9A0g5JSyStlrShetoGSRf0qEcADXhdH9DZXibpQ5K2SFoUEaPSxH8Ikqb84832WtsjtkcOabxmuwC6NeOw2z5W0h2SroqI/TNdLyLWRcRwRAzP0bxuegTQgBmF3fYcTQT91oi4s1q81/biqr5Y0lhvWgTQhGmH3mxb0s2SdkTElyeV7pF0iaTrqtu7e9Ih6jn9vcXyXy68pdbLf/WLFxbrb3n4/lqvj+bMZJx9paSLJT1ie2u17BpNhPw7ti+V9JSk8r86gFZNG/aIuE+SO5TParYdAL3C6bJAEoQdSIKwA0kQdiAJwg4kwSWuR4FZy9/Tsbb29nqnPyxff3mxvuyWf6v1+ugfjuxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kATj7EeBx/+48xf7nj9/xl8qNKWT//lg+QkRtV4f/cORHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSYJz9DeDF888o1jeff0OhOr/ZZtBzP9qztVj/xNtXdPW6HNmBJAg7kARhB5Ig7EAShB1IgrADSRB2IImZzM++VNK3JL1N0hFJ6yLiJtvXSvqspKerp14TERt71Whme1bOKtbfMbv7sfRbDyws1ufsL1/PztXs3SmNpXc7jj6dmZxUc1jS5yLiIdvHSXrQ9qaqdmNEfKknnQFo1EzmZx+VNFrdP2B7h6QlvW4MQLNe19/stpdJ+pCkLdWiK2xvs73e9pTfjWR7re0R2yOHNF6vWwBdm3HYbR8r6Q5JV0XEfklfk3SqpBWaOPJPeYJ2RKyLiOGIGJ6jefU7BtCVGYXd9hxNBP3WiLhTkiJib0S8FBFHJH1dUvlqDQCtmjbsti3pZkk7IuLLk5YvnvS0T0na3nx7AJoyk0/jV0q6WNIjtrdWy66RtMb2Ck2MvuySdFkP+kNNf/3s8mL9/k8sK9Zj9JEGu8mjzmWqvbrEdSafxt8nyVOUGFMH3kA4gw5IgrADSRB2IAnCDiRB2IEkCDuQhKOPU+4e7wVxps/q2/aAbLbEZu2PfVMNlXNkB7Ig7EAShB1IgrADSRB2IAnCDiRB2IEk+jrObvtpSf81adFJkp7pWwOvz6D2Nqh9SfTWrSZ7OyUi3jpVoa9hf83G7ZGIGG6tgYJB7W1Q+5LorVv96o238UAShB1Iou2wr2t5+yWD2tug9iXRW7f60lurf7MD6J+2j+wA+oSwA0m0Enbb59j+d9tP2L66jR46sb3L9iO2t9oeabmX9bbHbG+ftGyB7U22d1a3U86x11Jv19r+RbXvtto+r6Xeltr+ie0dth+1fWW1vNV9V+irL/ut73+z254l6T8knS1pt6QHJK2JiMf62kgHtndJGo6I1k/AsP3bkp6T9K2I+EC17HpJ+yLiuuo/yhMi4s8HpLdrJT3X9jTe1WxFiydPMy7pAkl/oBb3XaGv31Uf9lsbR/YzJD0REU9GxEFJt0ta3UIfAy8i7pW071WLV0vaUN3foIlflr7r0NtAiIjRiHioun9A0svTjLe67wp99UUbYV8i6eeTHu/WYM33HpJ+bPtB22vbbmYKiyJiVJr45ZG0sOV+Xm3aabz76VXTjA/Mvutm+vO62gj7VN+PNUjjfysj4jcknSvp8urtKmZmRtN498sU04wPhG6nP6+rjbDvlrR00uOTJe1poY8pRcSe6nZM0l0avKmo9748g251O9ZyP/9vkKbxnmqacQ3Avmtz+vM2wv6ApNNsv9P2XEkXSbqnhT5ew/ZQ9cGJbA9J+rgGbyrqeyRdUt2/RNLdLfbyCoMyjXenacbV8r5rffrziOj7j6TzNPGJ/M8k/UUbPXTo612SHq5+Hm27N0m3aeJt3SFNvCO6VNKJkjZL2lndLhig3m6R9IikbZoI1uKWevtNTfxpuE3S1urnvLb3XaGvvuw3TpcFkuAMOiAJwg4kQdiBJAg7kARhB5Ig7EAShB1I4v8A9RUAV2lh2uIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "backdoor = PoisoningAttackBackdoor(add_pattern_bd)\n",
    "example_target = np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 1])\n",
    "pdata, plabels = backdoor.poison(x_test, y=example_target)\n",
    "\n",
    "plt.imshow(pdata[0].squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ffec3ec",
   "metadata": {},
   "source": [
    "# Create the poison data\n",
    "For this example, we will select 9 as the target class. Thus, the adversary's goal is to poison the model so adding a trigger will result in the trained model misclassifying the triggered input as a 9.\n",
    "\n",
    "First, the adversary will create a proxy classifier (i.e., a classifier that is similar to the target classifier). As the clean label attack generates noise using PGD in order to encourage the trained classifier to rely on the trigger, it is important that the generated noise be transferable. Thus, adversarial training is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7aac5f5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e50398472be4255b52c267d1461ea2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Precompute adv samples:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a860befc4231453f9a788160d4f6d18f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adversarial training epochs:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Poison some percentage of all non-nines to nines\n",
    "targets = to_categorical([9], 10)[0] \n",
    "\n",
    "proxy = AdversarialTrainerMadryPGD(KerasClassifier(create_model()), nb_epochs=10, eps=0.15, eps_step=0.001)\n",
    "proxy.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46364ff1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df25857016e740f1816c54b5bf5507c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Random Initializations:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Iterations:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00abadf513c340538a0150378302e7fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Random Initializations:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Iterations:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f90d38b4f8b4371a009173867ea7d2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Random Initializations:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Iterations:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc9b20b9622641dd90fd72d3269fc56c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Random Initializations:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Iterations:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5680eac57a74592b65845ee8336570b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Random Initializations:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Iterations:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1765d499b7b4f8ab37a5e0be62ca0e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Random Initializations:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Iterations:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8292f5a4a0ce4abf8b7a3eaedab663cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Random Initializations:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Iterations:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "131b45f9cbd44661b045da9865ed58ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Random Initializations:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Iterations:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40ac0300c6004c10ae503e9af5c00dea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Random Initializations:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Iterations:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95517f5707d94b47b1f798c698624cf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Random Initializations:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Iterations:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dafbaca9819a4255a4adf0280a83ba3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Random Initializations:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Iterations:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "attack = PoisoningAttackCleanLabelBackdoor(backdoor=backdoor, proxy_classifier=proxy.get_classifier(),\n",
    "                                           target=targets, pp_poison=percent_poison, norm=2, eps=5,\n",
    "                                           eps_step=0.1, max_iter=200)\n",
    "pdata, plabels = attack.poison(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a61a524c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1042\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 290 Label: 9\n"
     ]
    }
   ],
   "source": [
    "poisoned = pdata[np.all(plabels == targets, axis=1)]\n",
    "poisoned_labels = plabels[np.all(plabels == targets, axis=1)]\n",
    "print(len(poisoned))\n",
    "for i in range(len(poisoned)):\n",
    "    if poisoned[i][0][0] != 0:\n",
    "        plt.imshow(poisoned[i].squeeze())\n",
    "        plt.show()\n",
    "        print(f\"Index: {i} Label: {np.argmax(poisoned_labels[i])}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8bbe9c",
   "metadata": {},
   "source": [
    "# Initialize the classification models\n",
    "We will initialize four models. The first is a single model architecture. The other three are DPA models with varying ensemble sizes to demonstrate the tradeoff between clean accuracy and poison accuracy. This make take some time because of the model copying."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "005f0374",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KerasClassifier(create_model())\n",
    "dpa_model_10 = DeepPartitionEnsemble(model, ensemble_size=10)\n",
    "dpa_model_20 = DeepPartitionEnsemble(model, ensemble_size=20)\n",
    "dpa_model_30 = DeepPartitionEnsemble(model, ensemble_size=30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0668c63f",
   "metadata": {},
   "source": [
    "Train the models on the poisoned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80f2917b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10000 samples\n",
      "Epoch 1/10\n",
      "10000/10000 [==============================] - 1s 109us/sample - loss: 0.6668 - accuracy: 0.7935\n",
      "Epoch 2/10\n",
      "10000/10000 [==============================] - 1s 53us/sample - loss: 0.2129 - accuracy: 0.9366\n",
      "Epoch 3/10\n",
      "10000/10000 [==============================] - 1s 54us/sample - loss: 0.1514 - accuracy: 0.9544\n",
      "Epoch 4/10\n",
      "10000/10000 [==============================] - 1s 53us/sample - loss: 0.1092 - accuracy: 0.9691\n",
      "Epoch 5/10\n",
      "10000/10000 [==============================] - 1s 52us/sample - loss: 0.0860 - accuracy: 0.9740\n",
      "Epoch 6/10\n",
      "10000/10000 [==============================] - 1s 52us/sample - loss: 0.0668 - accuracy: 0.9794\n",
      "Epoch 7/10\n",
      "10000/10000 [==============================] - 1s 52us/sample - loss: 0.0636 - accuracy: 0.9789\n",
      "Epoch 8/10\n",
      "10000/10000 [==============================] - 1s 52us/sample - loss: 0.0554 - accuracy: 0.9822\n",
      "Epoch 9/10\n",
      "10000/10000 [==============================] - 1s 54us/sample - loss: 0.0441 - accuracy: 0.9871\n",
      "Epoch 10/10\n",
      "10000/10000 [==============================] - 1s 53us/sample - loss: 0.0366 - accuracy: 0.9878\n",
      "Train on 963 samples\n",
      "Epoch 1/10\n",
      "963/963 [==============================] - 9s 10ms/sample - loss: 1.9348 - accuracy: 0.3593\n",
      "Epoch 2/10\n",
      "963/963 [==============================] - 0s 55us/sample - loss: 1.0212 - accuracy: 0.6646\n",
      "Epoch 3/10\n",
      "963/963 [==============================] - 0s 54us/sample - loss: 0.6831 - accuracy: 0.7850\n",
      "Epoch 4/10\n",
      "963/963 [==============================] - 0s 58us/sample - loss: 0.5596 - accuracy: 0.8245\n",
      "Epoch 5/10\n",
      "963/963 [==============================] - 0s 53us/sample - loss: 0.4262 - accuracy: 0.8640\n",
      "Epoch 6/10\n",
      "963/963 [==============================] - 0s 53us/sample - loss: 0.3805 - accuracy: 0.8795\n",
      "Epoch 7/10\n",
      "963/963 [==============================] - 0s 56us/sample - loss: 0.3167 - accuracy: 0.9034\n",
      "Epoch 8/10\n",
      "963/963 [==============================] - 0s 54us/sample - loss: 0.2656 - accuracy: 0.9211\n",
      "Epoch 9/10\n",
      "963/963 [==============================] - 0s 53us/sample - loss: 0.2042 - accuracy: 0.9398\n",
      "Epoch 10/10\n",
      "963/963 [==============================] - 0s 53us/sample - loss: 0.1519 - accuracy: 0.9470\n",
      "Train on 1000 samples\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 9s 9ms/sample - loss: 1.8922 - accuracy: 0.3860\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 0s 55us/sample - loss: 1.0128 - accuracy: 0.6770\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.6467 - accuracy: 0.7990\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 0s 53us/sample - loss: 0.4744 - accuracy: 0.8530\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 0s 67us/sample - loss: 0.3595 - accuracy: 0.8960\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 0s 53us/sample - loss: 0.3195 - accuracy: 0.9000\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 0s 53us/sample - loss: 0.2663 - accuracy: 0.9220\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 0s 53us/sample - loss: 0.2528 - accuracy: 0.9260\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.2115 - accuracy: 0.9390\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 0s 54us/sample - loss: 0.1582 - accuracy: 0.9570\n",
      "Train on 1057 samples\n",
      "Epoch 1/10\n",
      "1057/1057 [==============================] - 9s 9ms/sample - loss: 1.8447 - accuracy: 0.3860\n",
      "Epoch 2/10\n",
      "1057/1057 [==============================] - 0s 59us/sample - loss: 0.9678 - accuracy: 0.6717\n",
      "Epoch 3/10\n",
      "1057/1057 [==============================] - 0s 56us/sample - loss: 0.7032 - accuracy: 0.7588\n",
      "Epoch 4/10\n",
      "1057/1057 [==============================] - 0s 56us/sample - loss: 0.5346 - accuracy: 0.8269\n",
      "Epoch 5/10\n",
      "1057/1057 [==============================] - 0s 56us/sample - loss: 0.4131 - accuracy: 0.8675\n",
      "Epoch 6/10\n",
      "1057/1057 [==============================] - 0s 55us/sample - loss: 0.3383 - accuracy: 0.8931\n",
      "Epoch 7/10\n",
      "1057/1057 [==============================] - 0s 55us/sample - loss: 0.2952 - accuracy: 0.9139\n",
      "Epoch 8/10\n",
      "1057/1057 [==============================] - 0s 57us/sample - loss: 0.2469 - accuracy: 0.9205\n",
      "Epoch 9/10\n",
      "1057/1057 [==============================] - 0s 55us/sample - loss: 0.2121 - accuracy: 0.9338\n",
      "Epoch 10/10\n",
      "1057/1057 [==============================] - 0s 61us/sample - loss: 0.1670 - accuracy: 0.9489\n",
      "Train on 1032 samples\n",
      "Epoch 1/10\n",
      "1032/1032 [==============================] - 9s 9ms/sample - loss: 1.8166 - accuracy: 0.4254\n",
      "Epoch 2/10\n",
      "1032/1032 [==============================] - 0s 60us/sample - loss: 0.9565 - accuracy: 0.6841\n",
      "Epoch 3/10\n",
      "1032/1032 [==============================] - 0s 57us/sample - loss: 0.6313 - accuracy: 0.7994\n",
      "Epoch 4/10\n",
      "1032/1032 [==============================] - 0s 58us/sample - loss: 0.4817 - accuracy: 0.8440\n",
      "Epoch 5/10\n",
      "1032/1032 [==============================] - 0s 58us/sample - loss: 0.4146 - accuracy: 0.8750\n",
      "Epoch 6/10\n",
      "1032/1032 [==============================] - 0s 56us/sample - loss: 0.3367 - accuracy: 0.8905\n",
      "Epoch 7/10\n",
      "1032/1032 [==============================] - 0s 59us/sample - loss: 0.2960 - accuracy: 0.9138\n",
      "Epoch 8/10\n",
      "1032/1032 [==============================] - 0s 57us/sample - loss: 0.2549 - accuracy: 0.9225\n",
      "Epoch 9/10\n",
      "1032/1032 [==============================] - 0s 55us/sample - loss: 0.2414 - accuracy: 0.9264\n",
      "Epoch 10/10\n",
      "1032/1032 [==============================] - 0s 56us/sample - loss: 0.1950 - accuracy: 0.9486\n",
      "Train on 1020 samples\n",
      "Epoch 1/10\n",
      "1020/1020 [==============================] - 9s 9ms/sample - loss: 1.8730 - accuracy: 0.4039\n",
      "Epoch 2/10\n",
      "1020/1020 [==============================] - 0s 56us/sample - loss: 0.9344 - accuracy: 0.7029\n",
      "Epoch 3/10\n",
      "1020/1020 [==============================] - 0s 54us/sample - loss: 0.6400 - accuracy: 0.7912\n",
      "Epoch 4/10\n",
      "1020/1020 [==============================] - 0s 53us/sample - loss: 0.5197 - accuracy: 0.8324\n",
      "Epoch 5/10\n",
      "1020/1020 [==============================] - 0s 52us/sample - loss: 0.4154 - accuracy: 0.8696\n",
      "Epoch 6/10\n",
      "1020/1020 [==============================] - 0s 54us/sample - loss: 0.3371 - accuracy: 0.8824\n",
      "Epoch 7/10\n",
      "1020/1020 [==============================] - 0s 55us/sample - loss: 0.2922 - accuracy: 0.9098\n",
      "Epoch 8/10\n",
      "1020/1020 [==============================] - 0s 62us/sample - loss: 0.2364 - accuracy: 0.9294\n",
      "Epoch 9/10\n",
      "1020/1020 [==============================] - 0s 52us/sample - loss: 0.1839 - accuracy: 0.9461\n",
      "Epoch 10/10\n",
      "1020/1020 [==============================] - 0s 51us/sample - loss: 0.1587 - accuracy: 0.9412\n",
      "Train on 1005 samples\n",
      "Epoch 1/10\n",
      "1005/1005 [==============================] - 9s 9ms/sample - loss: 1.8552 - accuracy: 0.4269\n",
      "Epoch 2/10\n",
      "1005/1005 [==============================] - 0s 55us/sample - loss: 1.0098 - accuracy: 0.6726\n",
      "Epoch 3/10\n",
      "1005/1005 [==============================] - 0s 57us/sample - loss: 0.6585 - accuracy: 0.7791\n",
      "Epoch 4/10\n",
      "1005/1005 [==============================] - 0s 53us/sample - loss: 0.4911 - accuracy: 0.8388\n",
      "Epoch 5/10\n",
      "1005/1005 [==============================] - 0s 53us/sample - loss: 0.3979 - accuracy: 0.8697\n",
      "Epoch 6/10\n",
      "1005/1005 [==============================] - 0s 53us/sample - loss: 0.2860 - accuracy: 0.9045\n",
      "Epoch 7/10\n",
      "1005/1005 [==============================] - 0s 53us/sample - loss: 0.2859 - accuracy: 0.9075\n",
      "Epoch 8/10\n",
      "1005/1005 [==============================] - 0s 53us/sample - loss: 0.2305 - accuracy: 0.9274\n",
      "Epoch 9/10\n",
      "1005/1005 [==============================] - 0s 53us/sample - loss: 0.1840 - accuracy: 0.9403\n",
      "Epoch 10/10\n",
      "1005/1005 [==============================] - 0s 53us/sample - loss: 0.1750 - accuracy: 0.9433\n",
      "Train on 968 samples\n",
      "Epoch 1/10\n",
      "968/968 [==============================] - 9s 10ms/sample - loss: 1.8647 - accuracy: 0.3729\n",
      "Epoch 2/10\n",
      "968/968 [==============================] - 0s 58us/sample - loss: 0.9051 - accuracy: 0.7014\n",
      "Epoch 3/10\n",
      "968/968 [==============================] - 0s 55us/sample - loss: 0.6047 - accuracy: 0.7955\n",
      "Epoch 4/10\n",
      "968/968 [==============================] - 0s 55us/sample - loss: 0.4757 - accuracy: 0.8554\n",
      "Epoch 5/10\n",
      "968/968 [==============================] - 0s 55us/sample - loss: 0.3595 - accuracy: 0.8781\n",
      "Epoch 6/10\n",
      "968/968 [==============================] - 0s 65us/sample - loss: 0.3046 - accuracy: 0.9029\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "968/968 [==============================] - 0s 55us/sample - loss: 0.2729 - accuracy: 0.9070\n",
      "Epoch 8/10\n",
      "968/968 [==============================] - 0s 56us/sample - loss: 0.2170 - accuracy: 0.9277\n",
      "Epoch 9/10\n",
      "968/968 [==============================] - 0s 60us/sample - loss: 0.1661 - accuracy: 0.9473\n",
      "Epoch 10/10\n",
      "968/968 [==============================] - 0s 55us/sample - loss: 0.1444 - accuracy: 0.9473\n",
      "Train on 986 samples\n",
      "Epoch 1/10\n",
      "986/986 [==============================] - 9s 10ms/sample - loss: 1.8995 - accuracy: 0.3793\n",
      "Epoch 2/10\n",
      "986/986 [==============================] - 0s 57us/sample - loss: 0.9369 - accuracy: 0.6876\n",
      "Epoch 3/10\n",
      "986/986 [==============================] - 0s 60us/sample - loss: 0.6742 - accuracy: 0.7769\n",
      "Epoch 4/10\n",
      "986/986 [==============================] - 0s 54us/sample - loss: 0.5473 - accuracy: 0.8479\n",
      "Epoch 5/10\n",
      "986/986 [==============================] - 0s 53us/sample - loss: 0.4056 - accuracy: 0.8763\n",
      "Epoch 6/10\n",
      "986/986 [==============================] - 0s 57us/sample - loss: 0.3646 - accuracy: 0.8824\n",
      "Epoch 7/10\n",
      "986/986 [==============================] - 0s 54us/sample - loss: 0.3166 - accuracy: 0.8976\n",
      "Epoch 8/10\n",
      "986/986 [==============================] - 0s 54us/sample - loss: 0.2728 - accuracy: 0.9128\n",
      "Epoch 9/10\n",
      "986/986 [==============================] - 0s 53us/sample - loss: 0.2344 - accuracy: 0.9290\n",
      "Epoch 10/10\n",
      "986/986 [==============================] - 0s 53us/sample - loss: 0.1930 - accuracy: 0.9351\n",
      "Train on 991 samples\n",
      "Epoch 1/10\n",
      "991/991 [==============================] - 10s 10ms/sample - loss: 1.9182 - accuracy: 0.3824\n",
      "Epoch 2/10\n",
      "991/991 [==============================] - 0s 55us/sample - loss: 1.0203 - accuracy: 0.6842\n",
      "Epoch 3/10\n",
      "991/991 [==============================] - 0s 53us/sample - loss: 0.7130 - accuracy: 0.7709\n",
      "Epoch 4/10\n",
      "991/991 [==============================] - 0s 53us/sample - loss: 0.5373 - accuracy: 0.8385\n",
      "Epoch 5/10\n",
      "991/991 [==============================] - 0s 52us/sample - loss: 0.4151 - accuracy: 0.8840\n",
      "Epoch 6/10\n",
      "991/991 [==============================] - 0s 53us/sample - loss: 0.3558 - accuracy: 0.8799\n",
      "Epoch 7/10\n",
      "991/991 [==============================] - 0s 63us/sample - loss: 0.3103 - accuracy: 0.9082\n",
      "Epoch 8/10\n",
      "991/991 [==============================] - 0s 55us/sample - loss: 0.2769 - accuracy: 0.9092\n",
      "Epoch 9/10\n",
      "991/991 [==============================] - 0s 54us/sample - loss: 0.2179 - accuracy: 0.9314\n",
      "Epoch 10/10\n",
      "991/991 [==============================] - 0s 54us/sample - loss: 0.1640 - accuracy: 0.9516\n",
      "Train on 978 samples\n",
      "Epoch 1/10\n",
      "978/978 [==============================] - 10s 10ms/sample - loss: 1.8435 - accuracy: 0.3875\n",
      "Epoch 2/10\n",
      "978/978 [==============================] - 0s 57us/sample - loss: 0.9792 - accuracy: 0.6748\n",
      "Epoch 3/10\n",
      "978/978 [==============================] - 0s 55us/sample - loss: 0.6562 - accuracy: 0.7924\n",
      "Epoch 4/10\n",
      "978/978 [==============================] - 0s 55us/sample - loss: 0.5470 - accuracy: 0.8395\n",
      "Epoch 5/10\n",
      "978/978 [==============================] - 0s 56us/sample - loss: 0.4449 - accuracy: 0.8661\n",
      "Epoch 6/10\n",
      "978/978 [==============================] - 0s 53us/sample - loss: 0.3623 - accuracy: 0.8845\n",
      "Epoch 7/10\n",
      "978/978 [==============================] - 0s 54us/sample - loss: 0.3123 - accuracy: 0.8937\n",
      "Epoch 8/10\n",
      "978/978 [==============================] - 0s 63us/sample - loss: 0.2351 - accuracy: 0.9315\n",
      "Epoch 9/10\n",
      "978/978 [==============================] - 0s 55us/sample - loss: 0.2165 - accuracy: 0.9356\n",
      "Epoch 10/10\n",
      "978/978 [==============================] - 0s 54us/sample - loss: 0.1690 - accuracy: 0.9581\n",
      "Train on 481 samples\n",
      "Epoch 1/10\n",
      "481/481 [==============================] - 10s 20ms/sample - loss: 2.1775 - accuracy: 0.2183\n",
      "Epoch 2/10\n",
      "481/481 [==============================] - 0s 64us/sample - loss: 1.6444 - accuracy: 0.4990\n",
      "Epoch 3/10\n",
      "481/481 [==============================] - 0s 57us/sample - loss: 1.1730 - accuracy: 0.6133\n",
      "Epoch 4/10\n",
      "481/481 [==============================] - 0s 58us/sample - loss: 0.8438 - accuracy: 0.7256\n",
      "Epoch 5/10\n",
      "481/481 [==============================] - 0s 57us/sample - loss: 0.7197 - accuracy: 0.7630\n",
      "Epoch 6/10\n",
      "481/481 [==============================] - 0s 55us/sample - loss: 0.5893 - accuracy: 0.8212\n",
      "Epoch 7/10\n",
      "481/481 [==============================] - 0s 56us/sample - loss: 0.5090 - accuracy: 0.8337\n",
      "Epoch 8/10\n",
      "481/481 [==============================] - 0s 56us/sample - loss: 0.4340 - accuracy: 0.8565\n",
      "Epoch 9/10\n",
      "481/481 [==============================] - 0s 59us/sample - loss: 0.3860 - accuracy: 0.8690\n",
      "Epoch 10/10\n",
      "481/481 [==============================] - 0s 56us/sample - loss: 0.3088 - accuracy: 0.9210\n",
      "Train on 514 samples\n",
      "Epoch 1/10\n",
      "514/514 [==============================] - 10s 19ms/sample - loss: 2.1181 - accuracy: 0.2704\n",
      "Epoch 2/10\n",
      "514/514 [==============================] - 0s 66us/sample - loss: 1.4391 - accuracy: 0.5564\n",
      "Epoch 3/10\n",
      "514/514 [==============================] - 0s 62us/sample - loss: 1.0817 - accuracy: 0.6712\n",
      "Epoch 4/10\n",
      "514/514 [==============================] - 0s 63us/sample - loss: 0.8721 - accuracy: 0.7121\n",
      "Epoch 5/10\n",
      "514/514 [==============================] - 0s 64us/sample - loss: 0.7518 - accuracy: 0.7626\n",
      "Epoch 6/10\n",
      "514/514 [==============================] - 0s 65us/sample - loss: 0.6227 - accuracy: 0.8054\n",
      "Epoch 7/10\n",
      "514/514 [==============================] - 0s 61us/sample - loss: 0.5887 - accuracy: 0.8191\n",
      "Epoch 8/10\n",
      "514/514 [==============================] - 0s 61us/sample - loss: 0.5054 - accuracy: 0.8658\n",
      "Epoch 9/10\n",
      "514/514 [==============================] - 0s 59us/sample - loss: 0.3586 - accuracy: 0.8988\n",
      "Epoch 10/10\n",
      "514/514 [==============================] - 0s 60us/sample - loss: 0.3614 - accuracy: 0.8911\n",
      "Train on 523 samples\n",
      "Epoch 1/10\n",
      "523/523 [==============================] - 10s 18ms/sample - loss: 2.1203 - accuracy: 0.3327\n",
      "Epoch 2/10\n",
      "523/523 [==============================] - 0s 65us/sample - loss: 1.4263 - accuracy: 0.5813\n",
      "Epoch 3/10\n",
      "523/523 [==============================] - 0s 61us/sample - loss: 1.0224 - accuracy: 0.6750\n",
      "Epoch 4/10\n",
      "523/523 [==============================] - 0s 60us/sample - loss: 0.8609 - accuracy: 0.7228\n",
      "Epoch 5/10\n",
      "523/523 [==============================] - 0s 58us/sample - loss: 0.7089 - accuracy: 0.7514\n",
      "Epoch 6/10\n",
      "523/523 [==============================] - 0s 60us/sample - loss: 0.5944 - accuracy: 0.8031\n",
      "Epoch 7/10\n",
      "523/523 [==============================] - 0s 61us/sample - loss: 0.5785 - accuracy: 0.8164\n",
      "Epoch 8/10\n",
      "523/523 [==============================] - 0s 60us/sample - loss: 0.4617 - accuracy: 0.8489\n",
      "Epoch 9/10\n",
      "523/523 [==============================] - 0s 58us/sample - loss: 0.4921 - accuracy: 0.8394\n",
      "Epoch 10/10\n",
      "523/523 [==============================] - 0s 60us/sample - loss: 0.3318 - accuracy: 0.8987\n",
      "Train on 529 samples\n",
      "Epoch 1/10\n",
      "529/529 [==============================] - 10s 18ms/sample - loss: 2.1437 - accuracy: 0.2571\n",
      "Epoch 2/10\n",
      "529/529 [==============================] - 0s 64us/sample - loss: 1.4258 - accuracy: 0.5898\n",
      "Epoch 3/10\n",
      "529/529 [==============================] - 0s 62us/sample - loss: 0.9738 - accuracy: 0.7089\n",
      "Epoch 4/10\n",
      "529/529 [==============================] - 0s 62us/sample - loss: 0.7705 - accuracy: 0.7467\n",
      "Epoch 5/10\n",
      "529/529 [==============================] - 0s 60us/sample - loss: 0.6301 - accuracy: 0.8204\n",
      "Epoch 6/10\n",
      "529/529 [==============================] - 0s 61us/sample - loss: 0.4969 - accuracy: 0.8526\n",
      "Epoch 7/10\n",
      "529/529 [==============================] - 0s 62us/sample - loss: 0.4833 - accuracy: 0.8318\n",
      "Epoch 8/10\n",
      "529/529 [==============================] - 0s 60us/sample - loss: 0.3817 - accuracy: 0.8866\n",
      "Epoch 9/10\n",
      "529/529 [==============================] - 0s 60us/sample - loss: 0.3641 - accuracy: 0.8904\n",
      "Epoch 10/10\n",
      "529/529 [==============================] - 0s 59us/sample - loss: 0.2904 - accuracy: 0.9055\n",
      "Train on 528 samples\n",
      "Epoch 1/10\n",
      "528/528 [==============================] - 1s 1ms/sample - loss: 2.1489 - accuracy: 0.2519\n",
      "Epoch 2/10\n",
      "528/528 [==============================] - 0s 59us/sample - loss: 1.5087 - accuracy: 0.5265\n",
      "Epoch 3/10\n",
      "528/528 [==============================] - 0s 61us/sample - loss: 1.0105 - accuracy: 0.6610\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "528/528 [==============================] - 0s 60us/sample - loss: 0.8397 - accuracy: 0.7273\n",
      "Epoch 5/10\n",
      "528/528 [==============================] - 0s 62us/sample - loss: 0.7018 - accuracy: 0.7386\n",
      "Epoch 6/10\n",
      "528/528 [==============================] - 0s 60us/sample - loss: 0.6145 - accuracy: 0.7973\n",
      "Epoch 7/10\n",
      "528/528 [==============================] - 0s 58us/sample - loss: 0.5095 - accuracy: 0.8371\n",
      "Epoch 8/10\n",
      "528/528 [==============================] - 0s 59us/sample - loss: 0.4645 - accuracy: 0.8295\n",
      "Epoch 9/10\n",
      "528/528 [==============================] - 0s 60us/sample - loss: 0.4049 - accuracy: 0.8712\n",
      "Epoch 10/10\n",
      "528/528 [==============================] - 0s 57us/sample - loss: 0.3533 - accuracy: 0.8864\n",
      "Train on 505 samples\n",
      "Epoch 1/10\n",
      "505/505 [==============================] - 10s 20ms/sample - loss: 2.1431 - accuracy: 0.2337\n",
      "Epoch 2/10\n",
      "505/505 [==============================] - 0s 58us/sample - loss: 1.5446 - accuracy: 0.5564\n",
      "Epoch 3/10\n",
      "505/505 [==============================] - 0s 55us/sample - loss: 1.0494 - accuracy: 0.6950\n",
      "Epoch 4/10\n",
      "505/505 [==============================] - 0s 58us/sample - loss: 0.8355 - accuracy: 0.7287\n",
      "Epoch 5/10\n",
      "505/505 [==============================] - 0s 60us/sample - loss: 0.6153 - accuracy: 0.8119\n",
      "Epoch 6/10\n",
      "505/505 [==============================] - 0s 55us/sample - loss: 0.5346 - accuracy: 0.8297\n",
      "Epoch 7/10\n",
      "505/505 [==============================] - 0s 55us/sample - loss: 0.4651 - accuracy: 0.8554\n",
      "Epoch 8/10\n",
      "505/505 [==============================] - 0s 56us/sample - loss: 0.3967 - accuracy: 0.8515\n",
      "Epoch 9/10\n",
      "505/505 [==============================] - 0s 56us/sample - loss: 0.3255 - accuracy: 0.8911\n",
      "Epoch 10/10\n",
      "505/505 [==============================] - 0s 55us/sample - loss: 0.2694 - accuracy: 0.9149\n",
      "Train on 480 samples\n",
      "Epoch 1/10\n",
      "480/480 [==============================] - 10s 21ms/sample - loss: 2.1452 - accuracy: 0.2271\n",
      "Epoch 2/10\n",
      "480/480 [==============================] - 0s 59us/sample - loss: 1.4709 - accuracy: 0.6292\n",
      "Epoch 3/10\n",
      "480/480 [==============================] - 0s 57us/sample - loss: 0.8874 - accuracy: 0.7333\n",
      "Epoch 4/10\n",
      "480/480 [==============================] - 0s 57us/sample - loss: 0.6707 - accuracy: 0.7771\n",
      "Epoch 5/10\n",
      "480/480 [==============================] - 0s 55us/sample - loss: 0.5801 - accuracy: 0.8083\n",
      "Epoch 6/10\n",
      "480/480 [==============================] - 0s 56us/sample - loss: 0.4870 - accuracy: 0.8542\n",
      "Epoch 7/10\n",
      "480/480 [==============================] - 0s 63us/sample - loss: 0.3774 - accuracy: 0.8667\n",
      "Epoch 8/10\n",
      "480/480 [==============================] - 0s 57us/sample - loss: 0.3044 - accuracy: 0.9083\n",
      "Epoch 9/10\n",
      "480/480 [==============================] - 0s 55us/sample - loss: 0.2990 - accuracy: 0.8958\n",
      "Epoch 10/10\n",
      "480/480 [==============================] - 0s 56us/sample - loss: 0.2409 - accuracy: 0.9146\n",
      "Train on 468 samples\n",
      "Epoch 1/10\n",
      "468/468 [==============================] - 10s 21ms/sample - loss: 2.1546 - accuracy: 0.2799\n",
      "Epoch 2/10\n",
      "468/468 [==============================] - 0s 60us/sample - loss: 1.5467 - accuracy: 0.5449\n",
      "Epoch 3/10\n",
      "468/468 [==============================] - 0s 57us/sample - loss: 0.9986 - accuracy: 0.6838\n",
      "Epoch 4/10\n",
      "468/468 [==============================] - 0s 57us/sample - loss: 0.7478 - accuracy: 0.7585\n",
      "Epoch 5/10\n",
      "468/468 [==============================] - 0s 57us/sample - loss: 0.6031 - accuracy: 0.7991\n",
      "Epoch 6/10\n",
      "468/468 [==============================] - 0s 57us/sample - loss: 0.4572 - accuracy: 0.8654\n",
      "Epoch 7/10\n",
      "468/468 [==============================] - 0s 91us/sample - loss: 0.4436 - accuracy: 0.8654\n",
      "Epoch 8/10\n",
      "468/468 [==============================] - 0s 57us/sample - loss: 0.3346 - accuracy: 0.9017\n",
      "Epoch 9/10\n",
      "468/468 [==============================] - 0s 59us/sample - loss: 0.3536 - accuracy: 0.8761\n",
      "Epoch 10/10\n",
      "468/468 [==============================] - 0s 58us/sample - loss: 0.2524 - accuracy: 0.9103\n",
      "Train on 486 samples\n",
      "Epoch 1/10\n",
      "486/486 [==============================] - 10s 21ms/sample - loss: 2.1433 - accuracy: 0.2551\n",
      "Epoch 2/10\n",
      "486/486 [==============================] - 0s 60us/sample - loss: 1.4641 - accuracy: 0.5720\n",
      "Epoch 3/10\n",
      "486/486 [==============================] - 0s 77us/sample - loss: 1.0028 - accuracy: 0.6770\n",
      "Epoch 4/10\n",
      "486/486 [==============================] - 0s 56us/sample - loss: 0.8034 - accuracy: 0.7366\n",
      "Epoch 5/10\n",
      "486/486 [==============================] - 0s 56us/sample - loss: 0.6493 - accuracy: 0.7901\n",
      "Epoch 6/10\n",
      "486/486 [==============================] - 0s 57us/sample - loss: 0.5624 - accuracy: 0.8086\n",
      "Epoch 7/10\n",
      "486/486 [==============================] - 0s 55us/sample - loss: 0.5094 - accuracy: 0.8395\n",
      "Epoch 8/10\n",
      "486/486 [==============================] - 0s 57us/sample - loss: 0.4072 - accuracy: 0.8704\n",
      "Epoch 9/10\n",
      "486/486 [==============================] - 0s 55us/sample - loss: 0.3726 - accuracy: 0.8807\n",
      "Epoch 10/10\n",
      "486/486 [==============================] - 0s 56us/sample - loss: 0.2992 - accuracy: 0.9095\n",
      "Train on 495 samples\n",
      "Epoch 1/10\n",
      "495/495 [==============================] - 10s 20ms/sample - loss: 2.1340 - accuracy: 0.2586\n",
      "Epoch 2/10\n",
      "495/495 [==============================] - 0s 60us/sample - loss: 1.5234 - accuracy: 0.5737\n",
      "Epoch 3/10\n",
      "495/495 [==============================] - 0s 56us/sample - loss: 1.0101 - accuracy: 0.6727\n",
      "Epoch 4/10\n",
      "495/495 [==============================] - 0s 56us/sample - loss: 0.8037 - accuracy: 0.7313\n",
      "Epoch 5/10\n",
      "495/495 [==============================] - 0s 56us/sample - loss: 0.6052 - accuracy: 0.8040\n",
      "Epoch 6/10\n",
      "495/495 [==============================] - 0s 57us/sample - loss: 0.5539 - accuracy: 0.8424\n",
      "Epoch 7/10\n",
      "495/495 [==============================] - 0s 61us/sample - loss: 0.4627 - accuracy: 0.8586\n",
      "Epoch 8/10\n",
      "495/495 [==============================] - 0s 60us/sample - loss: 0.4110 - accuracy: 0.8727\n",
      "Epoch 9/10\n",
      "495/495 [==============================] - 0s 61us/sample - loss: 0.3609 - accuracy: 0.8869\n",
      "Epoch 10/10\n",
      "495/495 [==============================] - 0s 56us/sample - loss: 0.3141 - accuracy: 0.9091\n",
      "Train on 482 samples\n",
      "Epoch 1/10\n",
      "482/482 [==============================] - 10s 21ms/sample - loss: 2.1764 - accuracy: 0.2303\n",
      "Epoch 2/10\n",
      "482/482 [==============================] - 0s 60us/sample - loss: 1.5406 - accuracy: 0.5560\n",
      "Epoch 3/10\n",
      "482/482 [==============================] - 0s 57us/sample - loss: 1.0473 - accuracy: 0.6784\n",
      "Epoch 4/10\n",
      "482/482 [==============================] - 0s 56us/sample - loss: 0.8430 - accuracy: 0.7324\n",
      "Epoch 5/10\n",
      "482/482 [==============================] - 0s 56us/sample - loss: 0.6383 - accuracy: 0.8112\n",
      "Epoch 6/10\n",
      "482/482 [==============================] - 0s 64us/sample - loss: 0.5764 - accuracy: 0.8257\n",
      "Epoch 7/10\n",
      "482/482 [==============================] - 0s 58us/sample - loss: 0.4598 - accuracy: 0.8755\n",
      "Epoch 8/10\n",
      "482/482 [==============================] - 0s 59us/sample - loss: 0.3815 - accuracy: 0.8921\n",
      "Epoch 9/10\n",
      "482/482 [==============================] - 0s 57us/sample - loss: 0.3297 - accuracy: 0.9046\n",
      "Epoch 10/10\n",
      "482/482 [==============================] - 0s 59us/sample - loss: 0.2295 - accuracy: 0.9357\n",
      "Train on 486 samples\n",
      "Epoch 1/10\n",
      "486/486 [==============================] - 1s 1ms/sample - loss: 2.1878 - accuracy: 0.2366\n",
      "Epoch 2/10\n",
      "486/486 [==============================] - 0s 56us/sample - loss: 1.5752 - accuracy: 0.6214\n",
      "Epoch 3/10\n",
      "486/486 [==============================] - 0s 56us/sample - loss: 1.0463 - accuracy: 0.6708\n",
      "Epoch 4/10\n",
      "486/486 [==============================] - 0s 55us/sample - loss: 0.8246 - accuracy: 0.7366\n",
      "Epoch 5/10\n",
      "486/486 [==============================] - 0s 85us/sample - loss: 0.6613 - accuracy: 0.7757\n",
      "Epoch 6/10\n",
      "486/486 [==============================] - 0s 57us/sample - loss: 0.5554 - accuracy: 0.8189\n",
      "Epoch 7/10\n",
      "486/486 [==============================] - 0s 56us/sample - loss: 0.4802 - accuracy: 0.8395\n",
      "Epoch 8/10\n",
      "486/486 [==============================] - 0s 55us/sample - loss: 0.3758 - accuracy: 0.8827\n",
      "Epoch 9/10\n",
      "486/486 [==============================] - 0s 55us/sample - loss: 0.3418 - accuracy: 0.8930\n",
      "Epoch 10/10\n",
      "486/486 [==============================] - 0s 56us/sample - loss: 0.2939 - accuracy: 0.9012\n",
      "Train on 534 samples\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "534/534 [==============================] - 10s 19ms/sample - loss: 2.1621 - accuracy: 0.2154\n",
      "Epoch 2/10\n",
      "534/534 [==============================] - 0s 70us/sample - loss: 1.5126 - accuracy: 0.5056\n",
      "Epoch 3/10\n",
      "534/534 [==============================] - 0s 64us/sample - loss: 1.0817 - accuracy: 0.6217\n",
      "Epoch 4/10\n",
      "534/534 [==============================] - 0s 63us/sample - loss: 0.7903 - accuracy: 0.7509\n",
      "Epoch 5/10\n",
      "534/534 [==============================] - 0s 60us/sample - loss: 0.6815 - accuracy: 0.7884\n",
      "Epoch 6/10\n",
      "534/534 [==============================] - 0s 60us/sample - loss: 0.5505 - accuracy: 0.8296\n",
      "Epoch 7/10\n",
      "534/534 [==============================] - 0s 59us/sample - loss: 0.5044 - accuracy: 0.8446\n",
      "Epoch 8/10\n",
      "534/534 [==============================] - 0s 59us/sample - loss: 0.4086 - accuracy: 0.8727\n",
      "Epoch 9/10\n",
      "534/534 [==============================] - 0s 59us/sample - loss: 0.3429 - accuracy: 0.9064\n",
      "Epoch 10/10\n",
      "534/534 [==============================] - 0s 58us/sample - loss: 0.3056 - accuracy: 0.8970\n",
      "Train on 503 samples\n",
      "Epoch 1/10\n",
      "503/503 [==============================] - 10s 21ms/sample - loss: 2.1127 - accuracy: 0.3419\n",
      "Epoch 2/10\n",
      "503/503 [==============================] - 0s 60us/sample - loss: 1.4300 - accuracy: 0.5905\n",
      "Epoch 3/10\n",
      "503/503 [==============================] - 0s 56us/sample - loss: 0.9352 - accuracy: 0.7177\n",
      "Epoch 4/10\n",
      "503/503 [==============================] - 0s 56us/sample - loss: 0.7279 - accuracy: 0.7594\n",
      "Epoch 5/10\n",
      "503/503 [==============================] - 0s 57us/sample - loss: 0.5622 - accuracy: 0.8270\n",
      "Epoch 6/10\n",
      "503/503 [==============================] - 0s 56us/sample - loss: 0.4606 - accuracy: 0.8390\n",
      "Epoch 7/10\n",
      "503/503 [==============================] - 0s 55us/sample - loss: 0.3950 - accuracy: 0.8569\n",
      "Epoch 8/10\n",
      "503/503 [==============================] - 0s 55us/sample - loss: 0.3185 - accuracy: 0.9026\n",
      "Epoch 9/10\n",
      "503/503 [==============================] - 0s 62us/sample - loss: 0.2429 - accuracy: 0.9264\n",
      "Epoch 10/10\n",
      "503/503 [==============================] - 0s 55us/sample - loss: 0.2266 - accuracy: 0.9245\n",
      "Train on 492 samples\n",
      "Epoch 1/10\n",
      "492/492 [==============================] - 10s 21ms/sample - loss: 2.1539 - accuracy: 0.2927\n",
      "Epoch 2/10\n",
      "492/492 [==============================] - 0s 59us/sample - loss: 1.4890 - accuracy: 0.6504\n",
      "Epoch 3/10\n",
      "492/492 [==============================] - 0s 56us/sample - loss: 0.9864 - accuracy: 0.7093\n",
      "Epoch 4/10\n",
      "492/492 [==============================] - 0s 57us/sample - loss: 0.6970 - accuracy: 0.7683\n",
      "Epoch 5/10\n",
      "492/492 [==============================] - 0s 56us/sample - loss: 0.5769 - accuracy: 0.8110\n",
      "Epoch 6/10\n",
      "492/492 [==============================] - 0s 56us/sample - loss: 0.4525 - accuracy: 0.8720\n",
      "Epoch 7/10\n",
      "492/492 [==============================] - 0s 55us/sample - loss: 0.4082 - accuracy: 0.8598\n",
      "Epoch 8/10\n",
      "492/492 [==============================] - 0s 56us/sample - loss: 0.3098 - accuracy: 0.8984\n",
      "Epoch 9/10\n",
      "492/492 [==============================] - 0s 56us/sample - loss: 0.3037 - accuracy: 0.8943\n",
      "Epoch 10/10\n",
      "492/492 [==============================] - 0s 56us/sample - loss: 0.2356 - accuracy: 0.9167\n",
      "Train on 500 samples\n",
      "Epoch 1/10\n",
      "500/500 [==============================] - 11s 21ms/sample - loss: 2.1650 - accuracy: 0.2420\n",
      "Epoch 2/10\n",
      "500/500 [==============================] - 0s 59us/sample - loss: 1.5340 - accuracy: 0.5620\n",
      "Epoch 3/10\n",
      "500/500 [==============================] - 0s 56us/sample - loss: 1.0365 - accuracy: 0.6600\n",
      "Epoch 4/10\n",
      "500/500 [==============================] - 0s 56us/sample - loss: 0.8003 - accuracy: 0.7240\n",
      "Epoch 5/10\n",
      "500/500 [==============================] - 0s 57us/sample - loss: 0.6125 - accuracy: 0.7860\n",
      "Epoch 6/10\n",
      "500/500 [==============================] - 0s 57us/sample - loss: 0.5069 - accuracy: 0.8460\n",
      "Epoch 7/10\n",
      "500/500 [==============================] - 0s 57us/sample - loss: 0.4328 - accuracy: 0.8720\n",
      "Epoch 8/10\n",
      "500/500 [==============================] - 0s 57us/sample - loss: 0.3756 - accuracy: 0.8720\n",
      "Epoch 9/10\n",
      "500/500 [==============================] - 0s 57us/sample - loss: 0.3358 - accuracy: 0.8780\n",
      "Epoch 10/10\n",
      "500/500 [==============================] - 0s 56us/sample - loss: 0.2677 - accuracy: 0.9120\n",
      "Train on 488 samples\n",
      "Epoch 1/10\n",
      "488/488 [==============================] - 1s 1ms/sample - loss: 2.1246 - accuracy: 0.2807\n",
      "Epoch 2/10\n",
      "488/488 [==============================] - 0s 56us/sample - loss: 1.4881 - accuracy: 0.5615\n",
      "Epoch 3/10\n",
      "488/488 [==============================] - 0s 56us/sample - loss: 0.9723 - accuracy: 0.6988\n",
      "Epoch 4/10\n",
      "488/488 [==============================] - 0s 73us/sample - loss: 0.7687 - accuracy: 0.7275\n",
      "Epoch 5/10\n",
      "488/488 [==============================] - 0s 56us/sample - loss: 0.5672 - accuracy: 0.8258\n",
      "Epoch 6/10\n",
      "488/488 [==============================] - 0s 58us/sample - loss: 0.4588 - accuracy: 0.8566\n",
      "Epoch 7/10\n",
      "488/488 [==============================] - 0s 58us/sample - loss: 0.4122 - accuracy: 0.8504\n",
      "Epoch 8/10\n",
      "488/488 [==============================] - 0s 61us/sample - loss: 0.3228 - accuracy: 0.8975\n",
      "Epoch 9/10\n",
      "488/488 [==============================] - 0s 57us/sample - loss: 0.3162 - accuracy: 0.9098\n",
      "Epoch 10/10\n",
      "488/488 [==============================] - 0s 57us/sample - loss: 0.2826 - accuracy: 0.9139\n",
      "Train on 518 samples\n",
      "Epoch 1/10\n",
      "518/518 [==============================] - 11s 20ms/sample - loss: 2.1700 - accuracy: 0.2220\n",
      "Epoch 2/10\n",
      "518/518 [==============================] - 0s 64us/sample - loss: 1.5355 - accuracy: 0.5579\n",
      "Epoch 3/10\n",
      "518/518 [==============================] - 0s 62us/sample - loss: 1.0461 - accuracy: 0.6757\n",
      "Epoch 4/10\n",
      "518/518 [==============================] - 0s 113us/sample - loss: 0.8217 - accuracy: 0.7181\n",
      "Epoch 5/10\n",
      "518/518 [==============================] - 0s 62us/sample - loss: 0.7038 - accuracy: 0.7625\n",
      "Epoch 6/10\n",
      "518/518 [==============================] - 0s 61us/sample - loss: 0.5637 - accuracy: 0.8205\n",
      "Epoch 7/10\n",
      "518/518 [==============================] - 0s 63us/sample - loss: 0.5096 - accuracy: 0.8359\n",
      "Epoch 8/10\n",
      "518/518 [==============================] - 0s 63us/sample - loss: 0.4425 - accuracy: 0.8475\n",
      "Epoch 9/10\n",
      "518/518 [==============================] - 0s 61us/sample - loss: 0.3985 - accuracy: 0.8571\n",
      "Epoch 10/10\n",
      "518/518 [==============================] - 0s 62us/sample - loss: 0.3981 - accuracy: 0.8784\n",
      "Train on 505 samples\n",
      "Epoch 1/10\n",
      "505/505 [==============================] - 1s 1ms/sample - loss: 2.1348 - accuracy: 0.3030\n",
      "Epoch 2/10\n",
      "505/505 [==============================] - 0s 56us/sample - loss: 1.4776 - accuracy: 0.5584\n",
      "Epoch 3/10\n",
      "505/505 [==============================] - 0s 56us/sample - loss: 0.9705 - accuracy: 0.6832\n",
      "Epoch 4/10\n",
      "505/505 [==============================] - 0s 55us/sample - loss: 0.7680 - accuracy: 0.7465\n",
      "Epoch 5/10\n",
      "505/505 [==============================] - 0s 55us/sample - loss: 0.6106 - accuracy: 0.8079\n",
      "Epoch 6/10\n",
      "505/505 [==============================] - 0s 55us/sample - loss: 0.5002 - accuracy: 0.8218\n",
      "Epoch 7/10\n",
      "505/505 [==============================] - 0s 55us/sample - loss: 0.4429 - accuracy: 0.8535\n",
      "Epoch 8/10\n",
      "505/505 [==============================] - 0s 55us/sample - loss: 0.3665 - accuracy: 0.8812\n",
      "Epoch 9/10\n",
      "505/505 [==============================] - 0s 55us/sample - loss: 0.3601 - accuracy: 0.8851\n",
      "Epoch 10/10\n",
      "505/505 [==============================] - 0s 55us/sample - loss: 0.3121 - accuracy: 0.8970\n",
      "Train on 483 samples\n",
      "Epoch 1/10\n",
      "483/483 [==============================] - 11s 22ms/sample - loss: 2.1250 - accuracy: 0.2567\n",
      "Epoch 2/10\n",
      "483/483 [==============================] - 0s 60us/sample - loss: 1.4379 - accuracy: 0.5818\n",
      "Epoch 3/10\n",
      "483/483 [==============================] - 0s 63us/sample - loss: 0.9778 - accuracy: 0.6687\n",
      "Epoch 4/10\n",
      "483/483 [==============================] - 0s 59us/sample - loss: 0.7335 - accuracy: 0.7764\n",
      "Epoch 5/10\n",
      "483/483 [==============================] - 0s 57us/sample - loss: 0.5719 - accuracy: 0.8385\n",
      "Epoch 6/10\n",
      "483/483 [==============================] - 0s 63us/sample - loss: 0.4996 - accuracy: 0.8571\n",
      "Epoch 7/10\n",
      "483/483 [==============================] - 0s 57us/sample - loss: 0.4375 - accuracy: 0.8675\n",
      "Epoch 8/10\n",
      "483/483 [==============================] - 0s 56us/sample - loss: 0.3887 - accuracy: 0.8841\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "483/483 [==============================] - 0s 55us/sample - loss: 0.3106 - accuracy: 0.9110\n",
      "Epoch 10/10\n",
      "483/483 [==============================] - 0s 55us/sample - loss: 0.2805 - accuracy: 0.9110\n",
      "Train on 324 samples\n",
      "Epoch 1/10\n",
      "324/324 [==============================] - 11s 33ms/sample - loss: 2.2548 - accuracy: 0.1420\n",
      "Epoch 2/10\n",
      "324/324 [==============================] - 0s 67us/sample - loss: 1.8664 - accuracy: 0.4753\n",
      "Epoch 3/10\n",
      "324/324 [==============================] - 0s 61us/sample - loss: 1.4684 - accuracy: 0.5864\n",
      "Epoch 4/10\n",
      "324/324 [==============================] - 0s 69us/sample - loss: 1.1296 - accuracy: 0.6265\n",
      "Epoch 5/10\n",
      "324/324 [==============================] - 0s 63us/sample - loss: 0.8679 - accuracy: 0.7160\n",
      "Epoch 6/10\n",
      "324/324 [==============================] - 0s 61us/sample - loss: 0.7579 - accuracy: 0.7500\n",
      "Epoch 7/10\n",
      "324/324 [==============================] - 0s 60us/sample - loss: 0.7367 - accuracy: 0.7562\n",
      "Epoch 8/10\n",
      "324/324 [==============================] - 0s 63us/sample - loss: 0.6104 - accuracy: 0.8179\n",
      "Epoch 9/10\n",
      "324/324 [==============================] - 0s 61us/sample - loss: 0.5102 - accuracy: 0.8426\n",
      "Epoch 10/10\n",
      "324/324 [==============================] - 0s 63us/sample - loss: 0.4051 - accuracy: 0.8488\n",
      "Train on 323 samples\n",
      "Epoch 1/10\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 2.2306 - accuracy: 0.1734\n",
      "Epoch 2/10\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 1.7384 - accuracy: 0.5480\n",
      "Epoch 3/10\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 1.2520 - accuracy: 0.6563\n",
      "Epoch 4/10\n",
      "323/323 [==============================] - 0s 64us/sample - loss: 0.8496 - accuracy: 0.7492\n",
      "Epoch 5/10\n",
      "323/323 [==============================] - 0s 63us/sample - loss: 0.6620 - accuracy: 0.7709\n",
      "Epoch 6/10\n",
      "323/323 [==============================] - 0s 63us/sample - loss: 0.4981 - accuracy: 0.8483\n",
      "Epoch 7/10\n",
      "323/323 [==============================] - 0s 64us/sample - loss: 0.4409 - accuracy: 0.8390\n",
      "Epoch 8/10\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 0.3703 - accuracy: 0.8607\n",
      "Epoch 9/10\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 0.3235 - accuracy: 0.9040\n",
      "Epoch 10/10\n",
      "323/323 [==============================] - 0s 64us/sample - loss: 0.2937 - accuracy: 0.9071\n",
      "Train on 342 samples\n",
      "Epoch 1/10\n",
      "342/342 [==============================] - 11s 32ms/sample - loss: 2.2380 - accuracy: 0.1725\n",
      "Epoch 2/10\n",
      "342/342 [==============================] - 0s 65us/sample - loss: 1.8316 - accuracy: 0.4766\n",
      "Epoch 3/10\n",
      "342/342 [==============================] - 0s 60us/sample - loss: 1.4207 - accuracy: 0.5614\n",
      "Epoch 4/10\n",
      "342/342 [==============================] - 0s 66us/sample - loss: 1.1300 - accuracy: 0.6404\n",
      "Epoch 5/10\n",
      "342/342 [==============================] - 0s 59us/sample - loss: 0.8926 - accuracy: 0.7193\n",
      "Epoch 6/10\n",
      "342/342 [==============================] - 0s 58us/sample - loss: 0.7141 - accuracy: 0.7515\n",
      "Epoch 7/10\n",
      "342/342 [==============================] - 0s 61us/sample - loss: 0.6551 - accuracy: 0.7807\n",
      "Epoch 8/10\n",
      "342/342 [==============================] - 0s 61us/sample - loss: 0.5618 - accuracy: 0.8099\n",
      "Epoch 9/10\n",
      "342/342 [==============================] - 0s 59us/sample - loss: 0.4506 - accuracy: 0.8567\n",
      "Epoch 10/10\n",
      "342/342 [==============================] - 0s 61us/sample - loss: 0.3670 - accuracy: 0.8801\n",
      "Train on 325 samples\n",
      "Epoch 1/10\n",
      "325/325 [==============================] - 11s 34ms/sample - loss: 2.2454 - accuracy: 0.1569\n",
      "Epoch 2/10\n",
      "325/325 [==============================] - 0s 67us/sample - loss: 1.8617 - accuracy: 0.4585\n",
      "Epoch 3/10\n",
      "325/325 [==============================] - 0s 63us/sample - loss: 1.3664 - accuracy: 0.6154\n",
      "Epoch 4/10\n",
      "325/325 [==============================] - 0s 64us/sample - loss: 0.9389 - accuracy: 0.7138\n",
      "Epoch 5/10\n",
      "325/325 [==============================] - 0s 63us/sample - loss: 0.7995 - accuracy: 0.7508\n",
      "Epoch 6/10\n",
      "325/325 [==============================] - 0s 62us/sample - loss: 0.7195 - accuracy: 0.7600\n",
      "Epoch 7/10\n",
      "325/325 [==============================] - 0s 63us/sample - loss: 0.5517 - accuracy: 0.8554\n",
      "Epoch 8/10\n",
      "325/325 [==============================] - 0s 60us/sample - loss: 0.4940 - accuracy: 0.8585\n",
      "Epoch 9/10\n",
      "325/325 [==============================] - 0s 62us/sample - loss: 0.4365 - accuracy: 0.8800\n",
      "Epoch 10/10\n",
      "325/325 [==============================] - 0s 64us/sample - loss: 0.3165 - accuracy: 0.9077\n",
      "Train on 322 samples\n",
      "Epoch 1/10\n",
      "322/322 [==============================] - 11s 34ms/sample - loss: 2.2278 - accuracy: 0.1894\n",
      "Epoch 2/10\n",
      "322/322 [==============================] - 0s 69us/sample - loss: 1.7858 - accuracy: 0.5155\n",
      "Epoch 3/10\n",
      "322/322 [==============================] - 0s 65us/sample - loss: 1.2739 - accuracy: 0.6522\n",
      "Epoch 4/10\n",
      "322/322 [==============================] - 0s 64us/sample - loss: 0.9472 - accuracy: 0.6925\n",
      "Epoch 5/10\n",
      "322/322 [==============================] - 0s 62us/sample - loss: 0.8731 - accuracy: 0.7422\n",
      "Epoch 6/10\n",
      "322/322 [==============================] - 0s 61us/sample - loss: 0.6539 - accuracy: 0.7919\n",
      "Epoch 7/10\n",
      "322/322 [==============================] - 0s 66us/sample - loss: 0.5807 - accuracy: 0.8168\n",
      "Epoch 8/10\n",
      "322/322 [==============================] - 0s 63us/sample - loss: 0.4801 - accuracy: 0.8447\n",
      "Epoch 9/10\n",
      "322/322 [==============================] - 0s 66us/sample - loss: 0.4348 - accuracy: 0.8602\n",
      "Epoch 10/10\n",
      "322/322 [==============================] - 0s 62us/sample - loss: 0.2882 - accuracy: 0.9161\n",
      "Train on 347 samples\n",
      "Epoch 1/10\n",
      "347/347 [==============================] - 11s 32ms/sample - loss: 2.2546 - accuracy: 0.1210\n",
      "Epoch 2/10\n",
      "347/347 [==============================] - 0s 64us/sample - loss: 1.8273 - accuracy: 0.4841\n",
      "Epoch 3/10\n",
      "347/347 [==============================] - 0s 60us/sample - loss: 1.4393 - accuracy: 0.5620\n",
      "Epoch 4/10\n",
      "347/347 [==============================] - 0s 63us/sample - loss: 1.0664 - accuracy: 0.6571\n",
      "Epoch 5/10\n",
      "347/347 [==============================] - 0s 60us/sample - loss: 0.9386 - accuracy: 0.6916\n",
      "Epoch 6/10\n",
      "347/347 [==============================] - 0s 59us/sample - loss: 0.7910 - accuracy: 0.7493\n",
      "Epoch 7/10\n",
      "347/347 [==============================] - 0s 61us/sample - loss: 0.6547 - accuracy: 0.7983\n",
      "Epoch 8/10\n",
      "347/347 [==============================] - 0s 69us/sample - loss: 0.5288 - accuracy: 0.8559\n",
      "Epoch 9/10\n",
      "347/347 [==============================] - 0s 63us/sample - loss: 0.5278 - accuracy: 0.8127\n",
      "Epoch 10/10\n",
      "347/347 [==============================] - 0s 60us/sample - loss: 0.3877 - accuracy: 0.8761\n",
      "Train on 309 samples\n",
      "Epoch 1/10\n",
      "309/309 [==============================] - 11s 36ms/sample - loss: 2.2360 - accuracy: 0.2071\n",
      "Epoch 2/10\n",
      "309/309 [==============================] - 0s 70us/sample - loss: 1.7816 - accuracy: 0.5243\n",
      "Epoch 3/10\n",
      "309/309 [==============================] - 0s 65us/sample - loss: 1.2704 - accuracy: 0.6667\n",
      "Epoch 4/10\n",
      "309/309 [==============================] - 0s 64us/sample - loss: 0.9334 - accuracy: 0.6990\n",
      "Epoch 5/10\n",
      "309/309 [==============================] - 0s 63us/sample - loss: 0.7528 - accuracy: 0.7443\n",
      "Epoch 6/10\n",
      "309/309 [==============================] - 0s 64us/sample - loss: 0.6303 - accuracy: 0.7929\n",
      "Epoch 7/10\n",
      "309/309 [==============================] - 0s 63us/sample - loss: 0.5035 - accuracy: 0.8220\n",
      "Epoch 8/10\n",
      "309/309 [==============================] - 0s 78us/sample - loss: 0.4660 - accuracy: 0.8479\n",
      "Epoch 9/10\n",
      "309/309 [==============================] - 0s 70us/sample - loss: 0.4100 - accuracy: 0.8511\n",
      "Epoch 10/10\n",
      "309/309 [==============================] - 0s 73us/sample - loss: 0.3488 - accuracy: 0.8867\n",
      "Train on 308 samples\n",
      "Epoch 1/10\n",
      "308/308 [==============================] - 11s 36ms/sample - loss: 2.2350 - accuracy: 0.1786\n",
      "Epoch 2/10\n",
      "308/308 [==============================] - 0s 70us/sample - loss: 1.8466 - accuracy: 0.4351\n",
      "Epoch 3/10\n",
      "308/308 [==============================] - 0s 64us/sample - loss: 1.3188 - accuracy: 0.6169\n",
      "Epoch 4/10\n",
      "308/308 [==============================] - 0s 64us/sample - loss: 1.0252 - accuracy: 0.6526\n",
      "Epoch 5/10\n",
      "308/308 [==============================] - 0s 65us/sample - loss: 0.7959 - accuracy: 0.7370\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "308/308 [==============================] - 0s 63us/sample - loss: 0.7043 - accuracy: 0.7500\n",
      "Epoch 7/10\n",
      "308/308 [==============================] - 0s 64us/sample - loss: 0.5364 - accuracy: 0.8247\n",
      "Epoch 8/10\n",
      "308/308 [==============================] - 0s 64us/sample - loss: 0.4573 - accuracy: 0.8539\n",
      "Epoch 9/10\n",
      "308/308 [==============================] - 0s 65us/sample - loss: 0.4340 - accuracy: 0.8506\n",
      "Epoch 10/10\n",
      "308/308 [==============================] - 0s 64us/sample - loss: 0.3776 - accuracy: 0.8734\n",
      "Train on 335 samples\n",
      "Epoch 1/10\n",
      "335/335 [==============================] - 11s 34ms/sample - loss: 2.2041 - accuracy: 0.1881\n",
      "Epoch 2/10\n",
      "335/335 [==============================] - 0s 69us/sample - loss: 1.7178 - accuracy: 0.5134\n",
      "Epoch 3/10\n",
      "335/335 [==============================] - 0s 63us/sample - loss: 1.2325 - accuracy: 0.6418\n",
      "Epoch 4/10\n",
      "335/335 [==============================] - 0s 62us/sample - loss: 0.9610 - accuracy: 0.6955\n",
      "Epoch 5/10\n",
      "335/335 [==============================] - 0s 62us/sample - loss: 0.7274 - accuracy: 0.7433\n",
      "Epoch 6/10\n",
      "335/335 [==============================] - 0s 62us/sample - loss: 0.5745 - accuracy: 0.8030\n",
      "Epoch 7/10\n",
      "335/335 [==============================] - 0s 61us/sample - loss: 0.5069 - accuracy: 0.8507\n",
      "Epoch 8/10\n",
      "335/335 [==============================] - 0s 76us/sample - loss: 0.4238 - accuracy: 0.8687\n",
      "Epoch 9/10\n",
      "335/335 [==============================] - 0s 79us/sample - loss: 0.3895 - accuracy: 0.8836\n",
      "Epoch 10/10\n",
      "335/335 [==============================] - 0s 62us/sample - loss: 0.3400 - accuracy: 0.8925\n",
      "Train on 302 samples\n",
      "Epoch 1/10\n",
      "302/302 [==============================] - 11s 38ms/sample - loss: 2.2356 - accuracy: 0.1788\n",
      "Epoch 2/10\n",
      "302/302 [==============================] - 0s 70us/sample - loss: 1.8192 - accuracy: 0.4735\n",
      "Epoch 3/10\n",
      "302/302 [==============================] - 0s 64us/sample - loss: 1.3145 - accuracy: 0.6325\n",
      "Epoch 4/10\n",
      "302/302 [==============================] - 0s 62us/sample - loss: 0.9660 - accuracy: 0.6854\n",
      "Epoch 5/10\n",
      "302/302 [==============================] - 0s 63us/sample - loss: 0.8150 - accuracy: 0.7351\n",
      "Epoch 6/10\n",
      "302/302 [==============================] - 0s 63us/sample - loss: 0.6891 - accuracy: 0.7781\n",
      "Epoch 7/10\n",
      "302/302 [==============================] - 0s 64us/sample - loss: 0.5861 - accuracy: 0.8179\n",
      "Epoch 8/10\n",
      "302/302 [==============================] - 0s 63us/sample - loss: 0.5031 - accuracy: 0.8510\n",
      "Epoch 9/10\n",
      "302/302 [==============================] - 0s 68us/sample - loss: 0.4585 - accuracy: 0.8675\n",
      "Epoch 10/10\n",
      "302/302 [==============================] - 0s 64us/sample - loss: 0.4087 - accuracy: 0.8675\n",
      "Train on 315 samples\n",
      "Epoch 1/10\n",
      "315/315 [==============================] - 12s 37ms/sample - loss: 2.2341 - accuracy: 0.1810\n",
      "Epoch 2/10\n",
      "315/315 [==============================] - 0s 80us/sample - loss: 1.8170 - accuracy: 0.4159\n",
      "Epoch 3/10\n",
      "315/315 [==============================] - 0s 66us/sample - loss: 1.3814 - accuracy: 0.6095\n",
      "Epoch 4/10\n",
      "315/315 [==============================] - 0s 64us/sample - loss: 1.0259 - accuracy: 0.6730\n",
      "Epoch 5/10\n",
      "315/315 [==============================] - 0s 66us/sample - loss: 0.9151 - accuracy: 0.6825\n",
      "Epoch 6/10\n",
      "315/315 [==============================] - 0s 66us/sample - loss: 0.6886 - accuracy: 0.7524\n",
      "Epoch 7/10\n",
      "315/315 [==============================] - 0s 63us/sample - loss: 0.6590 - accuracy: 0.7841\n",
      "Epoch 8/10\n",
      "315/315 [==============================] - 0s 67us/sample - loss: 0.4832 - accuracy: 0.8635\n",
      "Epoch 9/10\n",
      "315/315 [==============================] - 0s 66us/sample - loss: 0.4498 - accuracy: 0.8635\n",
      "Epoch 10/10\n",
      "315/315 [==============================] - 0s 64us/sample - loss: 0.3939 - accuracy: 0.8762\n",
      "Train on 345 samples\n",
      "Epoch 1/10\n",
      "345/345 [==============================] - 12s 33ms/sample - loss: 2.2156 - accuracy: 0.1942\n",
      "Epoch 2/10\n",
      "345/345 [==============================] - 0s 71us/sample - loss: 1.7534 - accuracy: 0.5275\n",
      "Epoch 3/10\n",
      "345/345 [==============================] - 0s 66us/sample - loss: 1.2267 - accuracy: 0.6609\n",
      "Epoch 4/10\n",
      "345/345 [==============================] - 0s 62us/sample - loss: 0.9566 - accuracy: 0.6928\n",
      "Epoch 5/10\n",
      "345/345 [==============================] - 0s 63us/sample - loss: 0.7458 - accuracy: 0.7942\n",
      "Epoch 6/10\n",
      "345/345 [==============================] - 0s 72us/sample - loss: 0.6715 - accuracy: 0.7884\n",
      "Epoch 7/10\n",
      "345/345 [==============================] - 0s 60us/sample - loss: 0.5645 - accuracy: 0.8261\n",
      "Epoch 8/10\n",
      "345/345 [==============================] - 0s 60us/sample - loss: 0.4883 - accuracy: 0.8464\n",
      "Epoch 9/10\n",
      "345/345 [==============================] - 0s 63us/sample - loss: 0.4045 - accuracy: 0.8696\n",
      "Epoch 10/10\n",
      "345/345 [==============================] - 0s 62us/sample - loss: 0.3806 - accuracy: 0.8812\n",
      "Train on 360 samples\n",
      "Epoch 1/10\n",
      "360/360 [==============================] - 1s 2ms/sample - loss: 2.1870 - accuracy: 0.2000\n",
      "Epoch 2/10\n",
      "360/360 [==============================] - 0s 60us/sample - loss: 1.6846 - accuracy: 0.5583\n",
      "Epoch 3/10\n",
      "360/360 [==============================] - 0s 62us/sample - loss: 1.2173 - accuracy: 0.6028\n",
      "Epoch 4/10\n",
      "360/360 [==============================] - 0s 59us/sample - loss: 0.9515 - accuracy: 0.7028\n",
      "Epoch 5/10\n",
      "360/360 [==============================] - 0s 60us/sample - loss: 0.7086 - accuracy: 0.7806\n",
      "Epoch 6/10\n",
      "360/360 [==============================] - 0s 63us/sample - loss: 0.6152 - accuracy: 0.8056\n",
      "Epoch 7/10\n",
      "360/360 [==============================] - 0s 64us/sample - loss: 0.5507 - accuracy: 0.8139\n",
      "Epoch 8/10\n",
      "360/360 [==============================] - 0s 61us/sample - loss: 0.4329 - accuracy: 0.8611\n",
      "Epoch 9/10\n",
      "360/360 [==============================] - 0s 65us/sample - loss: 0.3778 - accuracy: 0.8944\n",
      "Epoch 10/10\n",
      "360/360 [==============================] - 0s 60us/sample - loss: 0.3881 - accuracy: 0.8778\n",
      "Train on 343 samples\n",
      "Epoch 1/10\n",
      "343/343 [==============================] - 12s 35ms/sample - loss: 2.2056 - accuracy: 0.2099\n",
      "Epoch 2/10\n",
      "343/343 [==============================] - 0s 67us/sample - loss: 1.7478 - accuracy: 0.4519\n",
      "Epoch 3/10\n",
      "343/343 [==============================] - 0s 64us/sample - loss: 1.2228 - accuracy: 0.6297\n",
      "Epoch 4/10\n",
      "343/343 [==============================] - 0s 62us/sample - loss: 0.9265 - accuracy: 0.7230\n",
      "Epoch 5/10\n",
      "343/343 [==============================] - 0s 62us/sample - loss: 0.7601 - accuracy: 0.7493\n",
      "Epoch 6/10\n",
      "343/343 [==============================] - 0s 63us/sample - loss: 0.5683 - accuracy: 0.8309\n",
      "Epoch 7/10\n",
      "343/343 [==============================] - 0s 64us/sample - loss: 0.4596 - accuracy: 0.8513\n",
      "Epoch 8/10\n",
      "343/343 [==============================] - 0s 63us/sample - loss: 0.3302 - accuracy: 0.8921\n",
      "Epoch 9/10\n",
      "343/343 [==============================] - 0s 61us/sample - loss: 0.2962 - accuracy: 0.9067\n",
      "Epoch 10/10\n",
      "343/343 [==============================] - 0s 61us/sample - loss: 0.2488 - accuracy: 0.9184\n",
      "Train on 342 samples\n",
      "Epoch 1/10\n",
      "342/342 [==============================] - 1s 2ms/sample - loss: 2.2205 - accuracy: 0.2398\n",
      "Epoch 2/10\n",
      "342/342 [==============================] - 0s 62us/sample - loss: 1.7411 - accuracy: 0.5673\n",
      "Epoch 3/10\n",
      "342/342 [==============================] - 0s 61us/sample - loss: 1.2467 - accuracy: 0.6404\n",
      "Epoch 4/10\n",
      "342/342 [==============================] - 0s 63us/sample - loss: 0.8607 - accuracy: 0.7222\n",
      "Epoch 5/10\n",
      "342/342 [==============================] - 0s 62us/sample - loss: 0.6752 - accuracy: 0.7865\n",
      "Epoch 6/10\n",
      "342/342 [==============================] - 0s 61us/sample - loss: 0.6142 - accuracy: 0.8070\n",
      "Epoch 7/10\n",
      "342/342 [==============================] - 0s 64us/sample - loss: 0.4820 - accuracy: 0.8509\n",
      "Epoch 8/10\n",
      "342/342 [==============================] - 0s 61us/sample - loss: 0.4223 - accuracy: 0.8713\n",
      "Epoch 9/10\n",
      "342/342 [==============================] - 0s 61us/sample - loss: 0.3845 - accuracy: 0.8801\n",
      "Epoch 10/10\n",
      "342/342 [==============================] - 0s 61us/sample - loss: 0.3521 - accuracy: 0.8567\n",
      "Train on 330 samples\n",
      "Epoch 1/10\n",
      "330/330 [==============================] - 12s 36ms/sample - loss: 2.2459 - accuracy: 0.2000\n",
      "Epoch 2/10\n",
      "330/330 [==============================] - 0s 68us/sample - loss: 1.8403 - accuracy: 0.5212\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "330/330 [==============================] - 0s 62us/sample - loss: 1.3075 - accuracy: 0.6303\n",
      "Epoch 4/10\n",
      "330/330 [==============================] - 0s 63us/sample - loss: 0.9618 - accuracy: 0.7091\n",
      "Epoch 5/10\n",
      "330/330 [==============================] - 0s 63us/sample - loss: 0.7600 - accuracy: 0.7576\n",
      "Epoch 6/10\n",
      "330/330 [==============================] - 0s 64us/sample - loss: 0.6339 - accuracy: 0.7848\n",
      "Epoch 7/10\n",
      "330/330 [==============================] - 0s 65us/sample - loss: 0.5387 - accuracy: 0.8182\n",
      "Epoch 8/10\n",
      "330/330 [==============================] - 0s 62us/sample - loss: 0.4587 - accuracy: 0.8576\n",
      "Epoch 9/10\n",
      "330/330 [==============================] - 0s 61us/sample - loss: 0.3809 - accuracy: 0.8848\n",
      "Epoch 10/10\n",
      "330/330 [==============================] - 0s 67us/sample - loss: 0.3699 - accuracy: 0.8697\n",
      "Train on 318 samples\n",
      "Epoch 1/10\n",
      "318/318 [==============================] - 12s 37ms/sample - loss: 2.1802 - accuracy: 0.2013\n",
      "Epoch 2/10\n",
      "318/318 [==============================] - 0s 71us/sample - loss: 1.7196 - accuracy: 0.5000\n",
      "Epoch 3/10\n",
      "318/318 [==============================] - 0s 66us/sample - loss: 1.1923 - accuracy: 0.6572\n",
      "Epoch 4/10\n",
      "318/318 [==============================] - 0s 64us/sample - loss: 0.8613 - accuracy: 0.6950\n",
      "Epoch 5/10\n",
      "318/318 [==============================] - 0s 66us/sample - loss: 0.7403 - accuracy: 0.7390\n",
      "Epoch 6/10\n",
      "318/318 [==============================] - 0s 65us/sample - loss: 0.5980 - accuracy: 0.7862\n",
      "Epoch 7/10\n",
      "318/318 [==============================] - 0s 66us/sample - loss: 0.4876 - accuracy: 0.8333\n",
      "Epoch 8/10\n",
      "318/318 [==============================] - 0s 84us/sample - loss: 0.4420 - accuracy: 0.8459\n",
      "Epoch 9/10\n",
      "318/318 [==============================] - 0s 64us/sample - loss: 0.3826 - accuracy: 0.8648\n",
      "Epoch 10/10\n",
      "318/318 [==============================] - 0s 65us/sample - loss: 0.3374 - accuracy: 0.8931\n",
      "Train on 344 samples\n",
      "Epoch 1/10\n",
      "344/344 [==============================] - 12s 35ms/sample - loss: 2.2292 - accuracy: 0.1570\n",
      "Epoch 2/10\n",
      "344/344 [==============================] - 0s 68us/sample - loss: 1.7692 - accuracy: 0.5174\n",
      "Epoch 3/10\n",
      "344/344 [==============================] - 0s 62us/sample - loss: 1.2617 - accuracy: 0.6308\n",
      "Epoch 4/10\n",
      "344/344 [==============================] - 0s 62us/sample - loss: 0.9609 - accuracy: 0.7151\n",
      "Epoch 5/10\n",
      "344/344 [==============================] - 0s 63us/sample - loss: 0.7661 - accuracy: 0.7471\n",
      "Epoch 6/10\n",
      "344/344 [==============================] - 0s 62us/sample - loss: 0.6832 - accuracy: 0.7878\n",
      "Epoch 7/10\n",
      "344/344 [==============================] - 0s 61us/sample - loss: 0.4812 - accuracy: 0.8430\n",
      "Epoch 8/10\n",
      "344/344 [==============================] - 0s 61us/sample - loss: 0.4927 - accuracy: 0.8488\n",
      "Epoch 9/10\n",
      "344/344 [==============================] - 0s 63us/sample - loss: 0.3984 - accuracy: 0.8808\n",
      "Epoch 10/10\n",
      "344/344 [==============================] - 0s 61us/sample - loss: 0.3699 - accuracy: 0.8866\n",
      "Train on 343 samples\n",
      "Epoch 1/10\n",
      "343/343 [==============================] - 1s 2ms/sample - loss: 2.1873 - accuracy: 0.2420\n",
      "Epoch 2/10\n",
      "343/343 [==============================] - 0s 63us/sample - loss: 1.6775 - accuracy: 0.5423\n",
      "Epoch 3/10\n",
      "343/343 [==============================] - 0s 61us/sample - loss: 1.1820 - accuracy: 0.6356\n",
      "Epoch 4/10\n",
      "343/343 [==============================] - 0s 61us/sample - loss: 0.9419 - accuracy: 0.6939\n",
      "Epoch 5/10\n",
      "343/343 [==============================] - 0s 63us/sample - loss: 0.7003 - accuracy: 0.7638\n",
      "Epoch 6/10\n",
      "343/343 [==============================] - 0s 60us/sample - loss: 0.5790 - accuracy: 0.8426\n",
      "Epoch 7/10\n",
      "343/343 [==============================] - 0s 62us/sample - loss: 0.4988 - accuracy: 0.8717\n",
      "Epoch 8/10\n",
      "343/343 [==============================] - 0s 61us/sample - loss: 0.4361 - accuracy: 0.8746\n",
      "Epoch 9/10\n",
      "343/343 [==============================] - 0s 62us/sample - loss: 0.3998 - accuracy: 0.8863\n",
      "Epoch 10/10\n",
      "343/343 [==============================] - 0s 63us/sample - loss: 0.3446 - accuracy: 0.8863\n",
      "Train on 333 samples\n",
      "Epoch 1/10\n",
      "333/333 [==============================] - 12s 36ms/sample - loss: 2.2107 - accuracy: 0.2012\n",
      "Epoch 2/10\n",
      "333/333 [==============================] - 0s 70us/sample - loss: 1.7116 - accuracy: 0.4925\n",
      "Epoch 3/10\n",
      "333/333 [==============================] - 0s 63us/sample - loss: 1.2445 - accuracy: 0.6096\n",
      "Epoch 4/10\n",
      "333/333 [==============================] - 0s 63us/sample - loss: 0.9491 - accuracy: 0.6877\n",
      "Epoch 5/10\n",
      "333/333 [==============================] - 0s 64us/sample - loss: 0.8191 - accuracy: 0.7297\n",
      "Epoch 6/10\n",
      "333/333 [==============================] - 0s 65us/sample - loss: 0.6393 - accuracy: 0.7838\n",
      "Epoch 7/10\n",
      "333/333 [==============================] - 0s 63us/sample - loss: 0.5971 - accuracy: 0.7868\n",
      "Epoch 8/10\n",
      "333/333 [==============================] - 0s 73us/sample - loss: 0.4872 - accuracy: 0.8408\n",
      "Epoch 9/10\n",
      "333/333 [==============================] - 0s 64us/sample - loss: 0.4835 - accuracy: 0.8559\n",
      "Epoch 10/10\n",
      "333/333 [==============================] - 0s 65us/sample - loss: 0.3642 - accuracy: 0.8829\n",
      "Train on 324 samples\n",
      "Epoch 1/10\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 2.2290 - accuracy: 0.1698\n",
      "Epoch 2/10\n",
      "324/324 [==============================] - 0s 64us/sample - loss: 1.8046 - accuracy: 0.4568\n",
      "Epoch 3/10\n",
      "324/324 [==============================] - 0s 64us/sample - loss: 1.3126 - accuracy: 0.5957\n",
      "Epoch 4/10\n",
      "324/324 [==============================] - 0s 66us/sample - loss: 0.9207 - accuracy: 0.7099\n",
      "Epoch 5/10\n",
      "324/324 [==============================] - 0s 64us/sample - loss: 0.7506 - accuracy: 0.7531\n",
      "Epoch 6/10\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 0.6467 - accuracy: 0.7870\n",
      "Epoch 7/10\n",
      "324/324 [==============================] - 0s 64us/sample - loss: 0.5215 - accuracy: 0.8210\n",
      "Epoch 8/10\n",
      "324/324 [==============================] - 0s 63us/sample - loss: 0.3789 - accuracy: 0.8920\n",
      "Epoch 9/10\n",
      "324/324 [==============================] - 0s 63us/sample - loss: 0.3973 - accuracy: 0.8642\n",
      "Epoch 10/10\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 0.3149 - accuracy: 0.8981\n",
      "Train on 332 samples\n",
      "Epoch 1/10\n",
      "332/332 [==============================] - 12s 37ms/sample - loss: 2.2283 - accuracy: 0.2018\n",
      "Epoch 2/10\n",
      "332/332 [==============================] - 0s 74us/sample - loss: 1.7522 - accuracy: 0.5301\n",
      "Epoch 3/10\n",
      "332/332 [==============================] - 0s 63us/sample - loss: 1.2310 - accuracy: 0.6386\n",
      "Epoch 4/10\n",
      "332/332 [==============================] - 0s 64us/sample - loss: 0.9724 - accuracy: 0.6928\n",
      "Epoch 5/10\n",
      "332/332 [==============================] - 0s 64us/sample - loss: 0.7570 - accuracy: 0.7440\n",
      "Epoch 6/10\n",
      "332/332 [==============================] - 0s 64us/sample - loss: 0.6688 - accuracy: 0.7831\n",
      "Epoch 7/10\n",
      "332/332 [==============================] - 0s 62us/sample - loss: 0.4865 - accuracy: 0.8554\n",
      "Epoch 8/10\n",
      "332/332 [==============================] - 0s 64us/sample - loss: 0.4305 - accuracy: 0.8524\n",
      "Epoch 9/10\n",
      "332/332 [==============================] - 0s 62us/sample - loss: 0.3408 - accuracy: 0.8916\n",
      "Epoch 10/10\n",
      "332/332 [==============================] - 0s 65us/sample - loss: 0.3165 - accuracy: 0.8916\n",
      "Train on 355 samples\n",
      "Epoch 1/10\n",
      "355/355 [==============================] - 1s 2ms/sample - loss: 2.2140 - accuracy: 0.2366\n",
      "Epoch 2/10\n",
      "355/355 [==============================] - 0s 63us/sample - loss: 1.7085 - accuracy: 0.5324\n",
      "Epoch 3/10\n",
      "355/355 [==============================] - 0s 61us/sample - loss: 1.2116 - accuracy: 0.6563\n",
      "Epoch 4/10\n",
      "355/355 [==============================] - 0s 61us/sample - loss: 0.8011 - accuracy: 0.7380\n",
      "Epoch 5/10\n",
      "355/355 [==============================] - 0s 61us/sample - loss: 0.7563 - accuracy: 0.7380\n",
      "Epoch 6/10\n",
      "355/355 [==============================] - 0s 62us/sample - loss: 0.5380 - accuracy: 0.8592\n",
      "Epoch 7/10\n",
      "355/355 [==============================] - 0s 61us/sample - loss: 0.5049 - accuracy: 0.8366\n",
      "Epoch 8/10\n",
      "355/355 [==============================] - 0s 61us/sample - loss: 0.4286 - accuracy: 0.8507\n",
      "Epoch 9/10\n",
      "355/355 [==============================] - 0s 61us/sample - loss: 0.3375 - accuracy: 0.8986\n",
      "Epoch 10/10\n",
      "355/355 [==============================] - 0s 62us/sample - loss: 0.3076 - accuracy: 0.8958\n",
      "Train on 364 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "364/364 [==============================] - 1s 2ms/sample - loss: 2.1992 - accuracy: 0.2308\n",
      "Epoch 2/10\n",
      "364/364 [==============================] - 0s 61us/sample - loss: 1.7003 - accuracy: 0.5412\n",
      "Epoch 3/10\n",
      "364/364 [==============================] - 0s 64us/sample - loss: 1.2034 - accuracy: 0.6538\n",
      "Epoch 4/10\n",
      "364/364 [==============================] - 0s 62us/sample - loss: 0.8895 - accuracy: 0.7170\n",
      "Epoch 5/10\n",
      "364/364 [==============================] - 0s 61us/sample - loss: 0.7179 - accuracy: 0.7637\n",
      "Epoch 6/10\n",
      "364/364 [==============================] - 0s 62us/sample - loss: 0.5412 - accuracy: 0.8324\n",
      "Epoch 7/10\n",
      "364/364 [==============================] - 0s 62us/sample - loss: 0.4449 - accuracy: 0.8654\n",
      "Epoch 8/10\n",
      "364/364 [==============================] - 0s 60us/sample - loss: 0.3979 - accuracy: 0.8819\n",
      "Epoch 9/10\n",
      "364/364 [==============================] - 0s 62us/sample - loss: 0.3312 - accuracy: 0.9038\n",
      "Epoch 10/10\n",
      "364/364 [==============================] - 0s 60us/sample - loss: 0.2683 - accuracy: 0.9148\n",
      "Train on 356 samples\n",
      "Epoch 1/10\n",
      "356/356 [==============================] - 12s 35ms/sample - loss: 2.1896 - accuracy: 0.2556\n",
      "Epoch 2/10\n",
      "356/356 [==============================] - 0s 66us/sample - loss: 1.6516 - accuracy: 0.5253\n",
      "Epoch 3/10\n",
      "356/356 [==============================] - 0s 61us/sample - loss: 1.2475 - accuracy: 0.6011\n",
      "Epoch 4/10\n",
      "356/356 [==============================] - 0s 60us/sample - loss: 0.9433 - accuracy: 0.6910\n",
      "Epoch 5/10\n",
      "356/356 [==============================] - 0s 62us/sample - loss: 0.7103 - accuracy: 0.7669\n",
      "Epoch 6/10\n",
      "356/356 [==============================] - 0s 62us/sample - loss: 0.6561 - accuracy: 0.7865\n",
      "Epoch 7/10\n",
      "356/356 [==============================] - 0s 60us/sample - loss: 0.5394 - accuracy: 0.8427\n",
      "Epoch 8/10\n",
      "356/356 [==============================] - 0s 63us/sample - loss: 0.4949 - accuracy: 0.8399\n",
      "Epoch 9/10\n",
      "356/356 [==============================] - 0s 63us/sample - loss: 0.3756 - accuracy: 0.8989\n",
      "Epoch 10/10\n",
      "356/356 [==============================] - 0s 67us/sample - loss: 0.3581 - accuracy: 0.8904\n",
      "Train on 328 samples\n",
      "Epoch 1/10\n",
      "328/328 [==============================] - 1s 3ms/sample - loss: 2.2195 - accuracy: 0.2256\n",
      "Epoch 2/10\n",
      "328/328 [==============================] - 0s 65us/sample - loss: 1.7603 - accuracy: 0.5305\n",
      "Epoch 3/10\n",
      "328/328 [==============================] - 0s 72us/sample - loss: 1.3121 - accuracy: 0.5976\n",
      "Epoch 4/10\n",
      "328/328 [==============================] - 0s 67us/sample - loss: 0.9780 - accuracy: 0.6982\n",
      "Epoch 5/10\n",
      "328/328 [==============================] - 0s 66us/sample - loss: 0.7637 - accuracy: 0.7470\n",
      "Epoch 6/10\n",
      "328/328 [==============================] - 0s 65us/sample - loss: 0.5870 - accuracy: 0.8018\n",
      "Epoch 7/10\n",
      "328/328 [==============================] - 0s 67us/sample - loss: 0.5439 - accuracy: 0.8110\n",
      "Epoch 8/10\n",
      "328/328 [==============================] - 0s 63us/sample - loss: 0.4581 - accuracy: 0.8750\n",
      "Epoch 9/10\n",
      "328/328 [==============================] - 0s 64us/sample - loss: 0.4408 - accuracy: 0.8445\n",
      "Epoch 10/10\n",
      "328/328 [==============================] - 0s 64us/sample - loss: 0.3448 - accuracy: 0.8994\n",
      "Train on 341 samples\n",
      "Epoch 1/10\n",
      "341/341 [==============================] - 13s 37ms/sample - loss: 2.2095 - accuracy: 0.2287\n",
      "Epoch 2/10\n",
      "341/341 [==============================] - 0s 77us/sample - loss: 1.7458 - accuracy: 0.5044\n",
      "Epoch 3/10\n",
      "341/341 [==============================] - 0s 66us/sample - loss: 1.2516 - accuracy: 0.6364\n",
      "Epoch 4/10\n",
      "341/341 [==============================] - 0s 64us/sample - loss: 0.9632 - accuracy: 0.6979\n",
      "Epoch 5/10\n",
      "341/341 [==============================] - 0s 64us/sample - loss: 0.7896 - accuracy: 0.7537\n",
      "Epoch 6/10\n",
      "341/341 [==============================] - 0s 67us/sample - loss: 0.5380 - accuracy: 0.8328\n",
      "Epoch 7/10\n",
      "341/341 [==============================] - 0s 63us/sample - loss: 0.5125 - accuracy: 0.8299\n",
      "Epoch 8/10\n",
      "341/341 [==============================] - 0s 66us/sample - loss: 0.4124 - accuracy: 0.8651\n",
      "Epoch 9/10\n",
      "341/341 [==============================] - 0s 61us/sample - loss: 0.3328 - accuracy: 0.8974\n",
      "Epoch 10/10\n",
      "341/341 [==============================] - 0s 63us/sample - loss: 0.3398 - accuracy: 0.8944\n",
      "Train on 334 samples\n",
      "Epoch 1/10\n",
      "334/334 [==============================] - 13s 38ms/sample - loss: 2.2204 - accuracy: 0.2186\n",
      "Epoch 2/10\n",
      "334/334 [==============================] - 0s 70us/sample - loss: 1.7547 - accuracy: 0.4880\n",
      "Epoch 3/10\n",
      "334/334 [==============================] - 0s 69us/sample - loss: 1.2073 - accuracy: 0.6317\n",
      "Epoch 4/10\n",
      "334/334 [==============================] - 0s 68us/sample - loss: 0.9725 - accuracy: 0.6617\n",
      "Epoch 5/10\n",
      "334/334 [==============================] - 0s 67us/sample - loss: 0.7449 - accuracy: 0.7515\n",
      "Epoch 6/10\n",
      "334/334 [==============================] - 0s 66us/sample - loss: 0.6154 - accuracy: 0.7994\n",
      "Epoch 7/10\n",
      "334/334 [==============================] - 0s 66us/sample - loss: 0.5448 - accuracy: 0.8204\n",
      "Epoch 8/10\n",
      "334/334 [==============================] - 0s 66us/sample - loss: 0.4493 - accuracy: 0.8533\n",
      "Epoch 9/10\n",
      "334/334 [==============================] - 0s 66us/sample - loss: 0.4034 - accuracy: 0.8533\n",
      "Epoch 10/10\n",
      "334/334 [==============================] - 0s 65us/sample - loss: 0.3736 - accuracy: 0.8802\n",
      "Train on 313 samples\n",
      "Epoch 1/10\n",
      "313/313 [==============================] - 13s 42ms/sample - loss: 2.2103 - accuracy: 0.1917\n",
      "Epoch 2/10\n",
      "313/313 [==============================] - 0s 71us/sample - loss: 1.6949 - accuracy: 0.5335\n",
      "Epoch 3/10\n",
      "313/313 [==============================] - 0s 68us/sample - loss: 1.3132 - accuracy: 0.5719\n",
      "Epoch 4/10\n",
      "313/313 [==============================] - 0s 69us/sample - loss: 0.9114 - accuracy: 0.7412\n",
      "Epoch 5/10\n",
      "313/313 [==============================] - 0s 74us/sample - loss: 0.7148 - accuracy: 0.7732\n",
      "Epoch 6/10\n",
      "313/313 [==============================] - 0s 68us/sample - loss: 0.5925 - accuracy: 0.8243\n",
      "Epoch 7/10\n",
      "313/313 [==============================] - 0s 66us/sample - loss: 0.5067 - accuracy: 0.8403\n",
      "Epoch 8/10\n",
      "313/313 [==============================] - 0s 69us/sample - loss: 0.4284 - accuracy: 0.8562\n",
      "Epoch 9/10\n",
      "313/313 [==============================] - 0s 68us/sample - loss: 0.3556 - accuracy: 0.8882\n",
      "Epoch 10/10\n",
      "313/313 [==============================] - 0s 70us/sample - loss: 0.3052 - accuracy: 0.8914\n",
      "Train on 343 samples\n",
      "Epoch 1/10\n",
      "343/343 [==============================] - 1s 3ms/sample - loss: 2.2128 - accuracy: 0.1924\n",
      "Epoch 2/10\n",
      "343/343 [==============================] - 0s 65us/sample - loss: 1.7686 - accuracy: 0.4577\n",
      "Epoch 3/10\n",
      "343/343 [==============================] - 0s 66us/sample - loss: 1.3149 - accuracy: 0.6093\n",
      "Epoch 4/10\n",
      "343/343 [==============================] - 0s 67us/sample - loss: 0.9948 - accuracy: 0.6822\n",
      "Epoch 5/10\n",
      "343/343 [==============================] - 0s 63us/sample - loss: 0.8470 - accuracy: 0.7230\n",
      "Epoch 6/10\n",
      "343/343 [==============================] - 0s 64us/sample - loss: 0.7368 - accuracy: 0.7609\n",
      "Epoch 7/10\n",
      "343/343 [==============================] - 0s 65us/sample - loss: 0.6659 - accuracy: 0.7930\n",
      "Epoch 8/10\n",
      "343/343 [==============================] - 0s 65us/sample - loss: 0.5063 - accuracy: 0.8280\n",
      "Epoch 9/10\n",
      "343/343 [==============================] - 0s 65us/sample - loss: 0.4646 - accuracy: 0.8484\n",
      "Epoch 10/10\n",
      "343/343 [==============================] - 0s 71us/sample - loss: 0.4105 - accuracy: 0.8688\n"
     ]
    }
   ],
   "source": [
    "model.fit(pdata, plabels, nb_epochs=10)\n",
    "dpa_model_10.fit(pdata, plabels, nb_epochs=10)\n",
    "dpa_model_20.fit(pdata, plabels, nb_epochs=10)\n",
    "dpa_model_30.fit(pdata, plabels, nb_epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7389971",
   "metadata": {},
   "source": [
    "# Evaluate the performance of the trained models on unpoisoned data\n",
    "The performance of the models appears normal. We see that for the DPA models, the performance drops slightly as the ensemble size increases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f63b588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Clean test set accuracy (model): 98.01%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 0\n"
     ]
    }
   ],
   "source": [
    "clean_preds = np.argmax(model.predict(x_test), axis=1)\n",
    "clean_correct = np.sum(clean_preds == np.argmax(y_test, axis=1))\n",
    "clean_total = y_test.shape[0]\n",
    "\n",
    "clean_acc = clean_correct / clean_total\n",
    "print(\"\\nClean test set accuracy (model): %.2f%%\" % (clean_acc * 100))\n",
    "\n",
    "# Display image, label, and prediction for a clean sample to show how the poisoned model classifies a clean sample\n",
    "\n",
    "c = 0 # class to display\n",
    "i = 0 # image of the class to display\n",
    "\n",
    "c_idx = np.where(np.argmax(y_test, 1) == c)[0][i] # index of the image in clean arrays\n",
    "\n",
    "plt.imshow(x_test[c_idx].squeeze())\n",
    "plt.show()\n",
    "clean_label = c\n",
    "print(\"Prediction: \" + str(clean_preds[c_idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f29f09a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Clean test set accuracy (DPA model_10): 93.94%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 0\n"
     ]
    }
   ],
   "source": [
    "clean_preds = np.argmax(dpa_model_10.predict(x_test), axis=1)\n",
    "clean_correct = np.sum(clean_preds == np.argmax(y_test, axis=1))\n",
    "clean_total = y_test.shape[0]\n",
    "\n",
    "clean_acc = clean_correct / clean_total\n",
    "print(\"\\nClean test set accuracy (DPA model_10): %.2f%%\" % (clean_acc * 100))\n",
    "\n",
    "# Display image, label, and prediction for a clean sample to show how the poisoned model classifies a clean sample\n",
    "\n",
    "c = 0 # class to display\n",
    "i = 0 # image of the class to display\n",
    "\n",
    "c_idx = np.where(np.argmax(y_test, 1) == c)[0][i] # index of the image in clean arrays\n",
    "\n",
    "plt.imshow(x_test[c_idx].squeeze())\n",
    "plt.show()\n",
    "clean_label = c\n",
    "print(\"Prediction: \" + str(clean_preds[c_idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af7b0bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Clean test set accuracy (DPA model_20): 91.32%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 0\n"
     ]
    }
   ],
   "source": [
    "clean_preds = np.argmax(dpa_model_20.predict(x_test), axis=1)\n",
    "clean_correct = np.sum(clean_preds == np.argmax(y_test, axis=1))\n",
    "clean_total = y_test.shape[0]\n",
    "\n",
    "clean_acc = clean_correct / clean_total\n",
    "print(\"\\nClean test set accuracy (DPA model_20): %.2f%%\" % (clean_acc * 100))\n",
    "\n",
    "# Display image, label, and prediction for a clean sample to show how the poisoned model classifies a clean sample\n",
    "\n",
    "c = 0 # class to display\n",
    "i = 0 # image of the class to display\n",
    "\n",
    "c_idx = np.where(np.argmax(y_test, 1) == c)[0][i] # index of the image in clean arrays\n",
    "\n",
    "plt.imshow(x_test[c_idx].squeeze())\n",
    "plt.show()\n",
    "clean_label = c\n",
    "print(\"Prediction: \" + str(clean_preds[c_idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d91009",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_preds = np.argmax(dpa_model_30.predict(x_test), axis=1)\n",
    "clean_correct = np.sum(clean_preds == np.argmax(y_test, axis=1))\n",
    "clean_total = y_test.shape[0]\n",
    "\n",
    "clean_acc = clean_correct / clean_total\n",
    "print(\"\\nClean test set accuracy (DPA model_30): %.2f%%\" % (clean_acc * 100))\n",
    "\n",
    "# Display image, label, and prediction for a clean sample to show how the poisoned model classifies a clean sample\n",
    "\n",
    "c = 0 # class to display\n",
    "i = 0 # image of the class to display\n",
    "\n",
    "c_idx = np.where(np.argmax(y_test, 1) == c)[0][i] # index of the image in clean arrays\n",
    "\n",
    "plt.imshow(x_test[c_idx].squeeze())\n",
    "plt.show()\n",
    "clean_label = c\n",
    "print(\"Prediction: \" + str(clean_preds[c_idx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44d4bf3",
   "metadata": {},
   "source": [
    "# Evaluate the performance of the trained models on poisoned data\n",
    "When the trigger is added, we see a shift in performance. The single model performs the worst as no defense is in place to mitigate the effect of the poisoned. The DPA models show some robustnesss to the poison as they partition the training data, which spreads the effect of the poison between models in the ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd59ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_target = np.logical_not(np.all(y_test == targets, axis=1))\n",
    "px_test, py_test = backdoor.poison(x_test[not_target], y_test[not_target])\n",
    "\n",
    "poison_preds = np.argmax(model.predict(px_test), axis=1)\n",
    "clean_correct = np.sum(poison_preds == np.argmax(y_test[not_target], axis=1))\n",
    "clean_total = y_test.shape[0]\n",
    "\n",
    "clean_acc = clean_correct / clean_total\n",
    "print(\"\\nPoison test set accuracy (model): %.2f%%\" % (clean_acc * 100))\n",
    "\n",
    "c = 0 # index to display\n",
    "plt.imshow(px_test[c].squeeze())\n",
    "plt.show()\n",
    "clean_label = c\n",
    "print(\"Prediction: \" + str(poison_preds[c]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500e4154",
   "metadata": {},
   "outputs": [],
   "source": [
    "poison_preds = np.argmax(dpa_model_10.predict(px_test), axis=1)\n",
    "clean_correct = np.sum(poison_preds == np.argmax(y_test[not_target], axis=1))\n",
    "clean_total = y_test.shape[0]\n",
    "\n",
    "clean_acc = clean_correct / clean_total\n",
    "print(\"\\nPoison test set accuracy (DPA model_10): %.2f%%\" % (clean_acc * 100))\n",
    "\n",
    "c = 0 # index to display\n",
    "plt.imshow(px_test[c].squeeze())\n",
    "plt.show()\n",
    "clean_label = c\n",
    "print(\"Prediction: \" + str(poison_preds[c]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e42d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "poison_preds = np.argmax(dpa_model_20.predict(px_test), axis=1)\n",
    "clean_correct = np.sum(poison_preds == np.argmax(y_test[not_target], axis=1))\n",
    "clean_total = y_test.shape[0]\n",
    "\n",
    "clean_acc = clean_correct / clean_total\n",
    "print(\"\\nPoison test set accuracy (DPA model_20): %.2f%%\" % (clean_acc * 100))\n",
    "\n",
    "c = 0 # index to display\n",
    "plt.imshow(px_test[c].squeeze())\n",
    "plt.show()\n",
    "clean_label = c\n",
    "print(\"Prediction: \" + str(poison_preds[c]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89dc71c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "poison_preds = np.argmax(dpa_model_30.predict(px_test), axis=1)\n",
    "clean_correct = np.sum(poison_preds == np.argmax(y_test[not_target], axis=1))\n",
    "clean_total = y_test.shape[0]\n",
    "\n",
    "clean_acc = clean_correct / clean_total\n",
    "print(\"\\nPoison test set accuracy (DPA model_30): %.2f%%\" % (clean_acc * 100))\n",
    "\n",
    "c = 0 # index to display\n",
    "plt.imshow(px_test[c].squeeze())\n",
    "plt.show()\n",
    "clean_label = c\n",
    "print(\"Prediction: \" + str(poison_preds[c]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3963c866",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
