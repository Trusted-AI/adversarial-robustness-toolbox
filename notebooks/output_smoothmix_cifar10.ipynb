{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aPIA-10zdv4P"
   },
   "source": [
    "## Training a Smoothed Classifier with SmoothMix Example\n",
    "\n",
    "This notebook shows how to use the ART implementation of SmoothMix training on randomized smoothing classifiers for certified robustness. The goal is to use this training scheme to control the robustness of smoothed classifiers via a *self-mixup*, where it trains on convex combinations of samples along the direction of adversarial perterbation for each input. Training the samples in this way offers an intuitive way to adaptively set a new decision boundary between these samples for better robustness. Full details of this training scheme can be found at https://arxiv.org/pdf/2111.09277.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset\n",
    "We will load the CIFAR10 dataset. We will also apply the same transformations that the author of the paper used on the dataset (Random Crop, Random Horizontal Flip). Afterward, we will convert the train and test sets to PyTorch tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets \n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "batch_size = 64\n",
    "train_data = datasets.CIFAR10(\n",
    "    \"./dataset_cache\", \n",
    "    train=True, \n",
    "    download=True, \n",
    "    transform=transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    ")\n",
    "test_data = datasets.CIFAR10(\n",
    "    \"./dataset_cache\", \n",
    "    train=False, \n",
    "    download=True, \n",
    "    transform=transforms.ToTensor()\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_data, \n",
    "    shuffle=True, \n",
    "    batch_size=batch_size, \n",
    "    num_workers=4\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_data, \n",
    "    shuffle=False, \n",
    "    batch_size=batch_size,\n",
    "    num_workers=4, \n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "# For train\n",
    "num_train_samples = 50000\n",
    "\n",
    "x_train = torch.zeros((num_train_samples, 3, 32, 32), dtype=torch.float32)\n",
    "y_train = torch.zeros((num_train_samples,), dtype=torch.uint8)\n",
    "\n",
    "for i,(data,labels) in enumerate(train_loader):\n",
    "    x_train[(i) * batch_size : (i+1) * batch_size, :, :, :] = data\n",
    "    y_train[(i) * batch_size : (i+1) * batch_size] = labels\n",
    "\n",
    "# For test\n",
    "num_train_samples = 10000\n",
    "\n",
    "x_test = torch.zeros((num_train_samples, 3, 32, 32), dtype=torch.float32)\n",
    "y_test = torch.zeros((num_train_samples,), dtype=torch.uint8)\n",
    "\n",
    "for i,(data,labels) in enumerate(test_loader):\n",
    "    x_test[(i) * batch_size : (i+1) * batch_size, :, :, :] = data\n",
    "    y_test[(i) * batch_size : (i+1) * batch_size] = labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define and Train Model\n",
    "We will use the ResNet-110 model from the original paper as our model to train. We temporarily save a model checkpoint to disk, in case we wish to use this trained model later on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \" 3x3 convolution with padding \"\n",
    "    return nn.Conv2d(\n",
    "        in_planes, \n",
    "        out_planes, \n",
    "        kernel_size=3, \n",
    "        stride=stride, \n",
    "        padding=1, \n",
    "        bias=False\n",
    "    )\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet_Cifar(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, width=1, num_classes=10):\n",
    "        super(ResNet_Cifar, self).__init__()\n",
    "        self.inplanes = 16\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.layer1 = self._make_layer(block, 16 * width, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 32 * width, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 64 * width, layers[2], stride=2)\n",
    "        self.avgpool = nn.AvgPool2d(8, stride=1)\n",
    "        self.fc = nn.Linear(64 * block.expansion * width, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, np.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                        kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion)\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "def resnet110(**kwargs):\n",
    "    model = ResNet_Cifar(BasicBlock, [18, 18, 18], width=1, **kwargs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from art.estimators.certification.randomized_smoothing import PyTorchRandomizedSmoothing\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "model = resnet110()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=1e-4)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "# SmoothMix params\n",
    "nb_epochs = 40\n",
    "batch_size = 128\n",
    "mix_step = 1\n",
    "eta = 5.0\n",
    "num_noise_vec = 2\n",
    "warmup = 10\n",
    "num_steps = 8\n",
    "mix_step = 0 # 0 for normal, 1 for smoothmix with one-step adv\n",
    "maxnorm_s = maxnorm = None\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train smoothed classifier, sigma = 0.25, alpha = 0.5\n",
    "sigma_1 = 0.25\n",
    "alpha_1 = 0.5\n",
    "\n",
    "rs_smoothmix_classifier_1 = PyTorchRandomizedSmoothing(\n",
    "    model=model,\n",
    "    loss=loss,\n",
    "    input_shape=(3, 32, 32),\n",
    "    nb_classes=10,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    clip_values=(0., 255.),\n",
    "    device_type=device,\n",
    "    alpha=alpha_1,\n",
    "    scale=sigma_1, \n",
    "    num_noise_vec=num_noise_vec,\n",
    "    train_multi_noise=True,\n",
    "    attack_type=\"PGD\",\n",
    "    num_steps=num_steps,\n",
    "    warmup=warmup,\n",
    "    eta=eta,\n",
    "    mix_step=mix_step,\n",
    "    maxnorm_s=maxnorm_s,\n",
    "    maxnorm=maxnorm\n",
    ")\n",
    "\n",
    "rs_smoothmix_classifier_1.fit(\n",
    "    x_train, y_train, nb_epochs=nb_epochs, batch_size=batch_size, train_method=\"smoothmix\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train smoothed classifier, sigma = 0.5, alpha = 1.0\n",
    "sigma_2 = 0.5\n",
    "alpha_2 = 1.0\n",
    "\n",
    "rs_smoothmix_classifier_2 = PyTorchRandomizedSmoothing(\n",
    "    model=model,\n",
    "    loss=loss,\n",
    "    input_shape=(3, 32, 32),\n",
    "    nb_classes=10,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    clip_values=(0., 255.),\n",
    "    device_type=device,\n",
    "    alpha=alpha_2,\n",
    "    scale=sigma_2, \n",
    "    num_noise_vec=num_noise_vec,\n",
    "    train_multi_noise=True,\n",
    "    attack_type=\"PGD\",\n",
    "    num_steps=num_steps,\n",
    "    warmup=warmup,\n",
    "    eta=eta,\n",
    "    mix_step=mix_step,\n",
    "    maxnorm_s=maxnorm_s,\n",
    "    maxnorm=maxnorm\n",
    ")\n",
    "\n",
    "rs_smoothmix_classifier_2.fit(\n",
    "    x_train, y_train, nb_epochs=nb_epochs, batch_size=batch_size, train_method=\"smoothmix\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kukXRDcedv4j"
   },
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from art.utils import compute_accuracy\n",
    "\n",
    "\n",
    "# Compute accuracy and coverage of the smoothed models\n",
    "x_preds_rs_1 = rs_smoothmix_classifier_1.predict(x_test)\n",
    "x_preds_rs_2 = rs_smoothmix_classifier_2.predict(x_test)\n",
    "\n",
    "acc_rs_1, cov_rs_1 = compute_accuracy(x_preds_rs_1, y_test)\n",
    "acc_rs_2, cov_rs_2 = compute_accuracy(x_preds_rs_2, y_test)\n",
    "\n",
    "print(\"\\nSmoothed Classifier, sigma=\" + str(sigma_1))\n",
    "print(\"Accuracy: {}\".format(acc_rs_1))\n",
    "print(\"Coverage: {}\".format(cov_rs_1))\n",
    "\n",
    "print(\"\\nSmoothed Classifier, sigma=\" + str(sigma_2))\n",
    "print(\"Accuracy: {}\".format(acc_rs_2))\n",
    "print(\"Coverage: {}\".format(cov_rs_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Certification of Accuracy and L2-Radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate certification accuracy for a given radius\n",
    "def getCertAcc(radius, pred, y_test):\n",
    "\n",
    "    rad_list = np.linspace(0, 2.25, 201)\n",
    "    cert_acc = []\n",
    "    num_cert = len(radius)\n",
    "    \n",
    "    for r in rad_list:\n",
    "        rad_idx = np.where(radius >= r)[0]\n",
    "        y_test_subset = y_test[rad_idx]\n",
    "        cert_acc.append(np.sum(pred[rad_idx] == np.argmax(y_test_subset, axis=1)) / num_cert)\n",
    "        \n",
    "    return cert_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_1, radius_1 = rs_smoothmix_classifier_1.certify(x_test, n=500)\n",
    "prediction_2, radius_2 = rs_smoothmix_classifier_2.certify(x_test, n=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# Plot certification accuracy w.r.t. to radius\n",
    "rad_list = np.linspace(0, 2.25, 201)\n",
    "plt.plot(rad_list, getCertAcc(radius_1, prediction_1, y_test), '-', color='green',\n",
    "         label='smoothed, $\\sigma=$' + str(sigma_1))\n",
    "plt.plot(rad_list, getCertAcc(radius_2, prediction_2, y_test), '-', color='blue',\n",
    "         label='smoothed, $\\sigma=$' + str(sigma_2))\n",
    "plt.xlabel('radius')\n",
    "plt.ylabel('certified accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "23b67459b6ba020d5027c3a663f4edb50823b29c309b6f3af1772b28309ae910"
  },
  "kernelspec": {
   "display_name": "Python 3.7.0 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
