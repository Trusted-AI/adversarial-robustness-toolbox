{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aPIA-10zdv4P"
   },
   "source": [
    "## ART SmoothMix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/6t/0jd7btxx6bl4xr75glctvn540000gn/T/ipykernel_45057/4000880293.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'TF_CPP_MIN_LOG_LEVEL'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'3'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR, MultiStepLR\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from art.utils import load_dataset, random_targets, compute_accuracy,load_cifar10\n",
    "from art.estimators.classification import PyTorchClassifier\n",
    "from art.estimators.certification.randomized_smoothing import PyTorchRandomizedSmoothing\n",
    "from art.data_generators import PyTorchDataGenerator\n",
    "\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.11.0+cu102\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA\n"
     ]
    }
   ],
   "source": [
    "use_gpu = torch.cuda.is_available()\n",
    "if use_gpu:\n",
    "    print(\"Using CUDA\")\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Load Data </h1>\n",
    "We are loading CIFAR10 dataset and applying transformations (random cropping, random horizontal flip, convert image to Tensor) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "train_data = datasets.CIFAR10(\n",
    "    \"./dataset_cache\", \n",
    "    train=True, \n",
    "    download=True, \n",
    "    transform=transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    ")\n",
    "test_data = datasets.CIFAR10(\n",
    "    \"./dataset_cache\", \n",
    "    train=False, \n",
    "    download=True, \n",
    "    transform=transforms.ToTensor()\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_data, \n",
    "    shuffle=True, \n",
    "    batch_size=batch_size, \n",
    "    num_workers=1\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_data, \n",
    "    shuffle=False, \n",
    "    batch_size=batch_size,\n",
    "    num_workers=1, \n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_samples = 50000\n",
    "\n",
    "x_train = torch.zeros((num_train_samples, 3, 32, 32), dtype=torch.float32)\n",
    "y_train = torch.zeros((num_train_samples,), dtype=torch.uint8)\n",
    "\n",
    "for i,(data,labels) in enumerate(train_loader):\n",
    "    x_train[(i) * batch_size : (i+1) * batch_size, :, :, :] = data\n",
    "    y_train[(i) * batch_size : (i+1) * batch_size] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_samples = 10000\n",
    "\n",
    "x_test = torch.zeros((num_train_samples, 3, 32, 32), dtype=torch.float32)\n",
    "y_test = torch.zeros((num_train_samples,), dtype=torch.uint8)\n",
    "\n",
    "for i,(data,labels) in enumerate(test_loader):\n",
    "    x_test[(i) * batch_size : (i+1) * batch_size, :, :, :] = data\n",
    "    y_test[(i) * batch_size : (i+1) * batch_size] = labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Train SmoothMix Classifier </h3>\n",
    "\n",
    "Training the smoothmix classifier. Building the model first using the ResNet110 architecture. Then the optimizer and scheduler functions are defined along with the Randomized Smoothing class object. The fit invocation trains the model on the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \" 3x3 convolution with padding \"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet_Cifar(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, width=1, num_classes=10):\n",
    "        super(ResNet_Cifar, self).__init__()\n",
    "        self.inplanes = 16\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.layer1 = self._make_layer(block, 16 * width, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 32 * width, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 64 * width, layers[2], stride=2)\n",
    "        self.avgpool = nn.AvgPool2d(8, stride=1)\n",
    "        self.fc = nn.Linear(64 * block.expansion * width, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, np.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                        kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion)\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "def resnet110(**kwargs):\n",
    "    model = ResNet_Cifar(BasicBlock, [18, 18, 18], width=1, **kwargs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet110()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=1e-4)\n",
    "scheduler = StepLR(optimizer, step_size=50, gamma=0.1)\n",
    "loss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SmoothMix params\n",
    "sigma = 0.25\n",
    "alpha = 0.5\n",
    "mix_step = 1\n",
    "eta = 5.0\n",
    "num_noise_vec = 2\n",
    "warmup = 10\n",
    "num_steps = 8\n",
    "mix_step = 0 # 0 for normal, 1 for smoothmix with one-step adv\n",
    "maxnorm_s = maxnorm = None\n",
    "\n",
    "rs_smoothmix_classifier = PyTorchRandomizedSmoothing(\n",
    "    model=model,\n",
    "    loss=loss,\n",
    "    input_shape=(3, 32, 32),\n",
    "    nb_classes=10,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    clip_values=(0.0, 255.0),\n",
    "    device_type=device,\n",
    "    alpha=alpha,\n",
    "    scale=sigma, \n",
    "    num_noise_vec=num_noise_vec,\n",
    "    train_multi_noise=True,\n",
    "    attack_type=\"PGD\",\n",
    "    num_steps=num_steps,\n",
    "    warmup=warmup,\n",
    "    eta=eta,\n",
    "    mix_step=mix_step,\n",
    "    maxnorm_s=maxnorm_s,\n",
    "    maxnorm=maxnorm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_smoothmix_classifier.fit(\n",
    "    x_train, \n",
    "    y_train, \n",
    "    nb_epochs=150, \n",
    "    batch_size=256, \n",
    "    train_method='smoothmix'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Predictions for Trained Model </h3>\n",
    "\n",
    "Predicting on the test dataset using the trained model. The accuracy and coverage for the trained model is observed. Coverage refers to the percentage number of instances that could be classified and the model did not abstain from providing a predicted label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_encoded = F.one_hot(y_test.to(torch.int64))\n",
    "x_preds_rs_1 = rs_smoothmix_classifier.predict(x_test[:500])\n",
    "acc_rs_1, cov_rs_1 = compute_accuracy(x_preds_rs_1, y_test_encoded[:500].numpy())\n",
    "print(\"\\nSmoothMix Classifier, sigma=\" + str(sigma))\n",
    "print(\"Accuracy: {}\".format(acc_rs_1))\n",
    "print(\"Coverage: {}\".format(cov_rs_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Certified Radius for Single Image</h3>\n",
    "\n",
    "Calculating the certified radius on a single image. The image index to be used is used randomly from the 10000 test images. To use any particular image, use the corresponding image's index below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCertAcc(radius, pred, y_test):\n",
    "    \"\"\"\n",
    "    Calculate certification accuracy for a given radius\n",
    "    \"\"\"\n",
    "    rad_list = np.linspace(0, 2.25, 201)\n",
    "    cert_acc = []\n",
    "    num_cert = len(radius)\n",
    "    for r in rad_list:\n",
    "        rad_idx = np.where(radius >= r)[0]\n",
    "        y_test_subset = y_test[rad_idx]\n",
    "        cert_acc.append(np.sum(pred[rad_idx] == y_test_subset) / num_cert)\n",
    "    return cert_acc\n",
    "\n",
    "def calculateACR(target, prediction, radius):\n",
    "    tot = 0\n",
    "    cnt = 0\n",
    "    for i in range(0, len(prediction)):\n",
    "        if(prediction[i] == target[i]):\n",
    "            tot += radius[i]\n",
    "        cnt += 1\n",
    "    return tot/cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#single image certification return certified radius, index or random) \n",
    "import random \n",
    "index = random.randint(0,9999)\n",
    "x_sample = x_test[index].expand((1,3,32,32))\n",
    "prediction, radius = rs_smoothmix_classifier.certify(x_sample, n = 100000)\n",
    "print(\"Prediction: {} and Radius: {}\".format(prediction,radius))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Certification on Test Images</h3>\n",
    "\n",
    "Performing and observing the certification over all the test dataset consisting of 10000 images. The ACR (Average Certified Radius) is computed for the certification results to understand results better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no.of test images for ACR/graph (ACR inside the graph)\n",
    "start_img = 500\n",
    "num_img = 500\n",
    "skip = 1\n",
    "N = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_1, radius_1 = rs_smoothmix_classifier.certify(\n",
    "    x_test[(start_img-1):(start_img-1)+(num_img*skip):skip], \n",
    "    n=N\n",
    ")\n",
    "acr = calculateACR(\n",
    "    target=np.array(y_test[(start_img-1):(start_img-1)+(num_img*skip):skip]), \n",
    "    prediction=np.array(prediction_1), \n",
    "    radius=np.array(radius_1))\n",
    "print(\"ACR for Smooth Adversarial Classifier: \", acr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rad_list = np.linspace(0, 2.25, 201)\n",
    "plt.plot(rad_list, getCertAcc(radius_1, prediction_1, np.array(y_test)), 'r-', label='smoothed, $\\sigma=$' + str(sigma_1))\n",
    "plt.xlabel('L2 radius')\n",
    "plt.ylabel('Certified Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Average Certified Radius plot: ACR {}'.format(acr))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
