{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running membership inference attacks on the Nursery data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial we will show how to run black-box membership attacks. This will be demonstrated on the Nursery dataset (original dataset can be found here: https://archive.ics.uci.edu/ml/datasets/nursery). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have already preprocessed the dataset such that all categorical features are one-hot encoded, and the data was scaled using sklearn's StandardScaler."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "\n",
    "from art.utils import load_nursery\n",
    "\n",
    "(x_train, y_train), (x_test, y_test), _, _ = load_nursery(test_set=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train random forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base model accuracy:  0.9739117011423278\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from art.estimators.classification.scikitlearn import ScikitlearnRandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "art_classifier = ScikitlearnRandomForestClassifier(model)\n",
    "\n",
    "print('Base model accuracy: ', model.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attack\n",
    "### Rule-based attack\n",
    "The rule-based attack uses the simple rule to determine membership in the training data: if the model's prediction for a sample is correct, then it is a member. Otherwise, it is not a member."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.026088298857672165\n",
      "0.513044149428836\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from art.attacks.inference.membership_inference import MembershipInferenceBlackBoxRuleBased\n",
    "\n",
    "attack = MembershipInferenceBlackBoxRuleBased(art_classifier)\n",
    "\n",
    "# infer attacked feature\n",
    "inferred_train = attack.infer(x_train, y_train)\n",
    "inferred_test = attack.infer(x_test, y_test)\n",
    "\n",
    "# check accuracy\n",
    "train_acc = np.sum(inferred_train) / len(inferred_train)\n",
    "test_acc = 1 - (np.sum(inferred_test) / len(inferred_test))\n",
    "acc = (train_acc * len(inferred_train) + test_acc * len(inferred_test)) / (len(inferred_train) + len(inferred_test))\n",
    "print(train_acc)\n",
    "print(test_acc)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that for 51% of the data, membership status is inferred correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.50660827402831, 1.0)\n"
     ]
    }
   ],
   "source": [
    "def calc_precision_recall(predicted, actual, positive_value=1):\n",
    "    score = 0  # both predicted and actual are positive\n",
    "    num_positive_predicted = 0  # predicted positive\n",
    "    num_positive_actual = 0  # actual positive\n",
    "    for i in range(len(predicted)):\n",
    "        if predicted[i] == positive_value:\n",
    "            num_positive_predicted += 1\n",
    "        if actual[i] == positive_value:\n",
    "            num_positive_actual += 1\n",
    "        if predicted[i] == actual[i]:\n",
    "            if predicted[i] == positive_value:\n",
    "                score += 1\n",
    "    \n",
    "    if num_positive_predicted == 0:\n",
    "        precision = 1\n",
    "    else:\n",
    "        precision = score / num_positive_predicted  # the fraction of predicted “Yes” responses that are correct\n",
    "    if num_positive_actual == 0:\n",
    "        recall = 1\n",
    "    else:\n",
    "        recall = score / num_positive_actual  # the fraction of “Yes” responses that are predicted correctly\n",
    "\n",
    "    return precision, recall\n",
    "\n",
    "# rule-based\n",
    "print(calc_precision_recall(np.concatenate((inferred_train, inferred_test)), \n",
    "                            np.concatenate((np.ones(len(inferred_train)), np.zeros(len(inferred_test))))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Black-box attack\n",
    "The black-box attack basically trains an additional classifier (called the attack model) to predict the membership status of a sample. It can use as input to the learning process probabilities/logits or losses, depending on the type of model and provided configuration.\n",
    "#### Train attack model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from art.attacks.inference.membership_inference import MembershipInferenceBlackBox\n",
    "\n",
    "attack_train_ratio = 0.5\n",
    "attack_train_size = int(len(x_train) * attack_train_ratio)\n",
    "attack_test_size = int(len(x_test) * attack_train_ratio)\n",
    "\n",
    "bb_attack = MembershipInferenceBlackBox(art_classifier)\n",
    "\n",
    "# train attack model\n",
    "bb_attack.fit(x_train[:attack_train_size], y_train[:attack_train_size],\n",
    "              x_test[:attack_test_size], y_test[:attack_test_size])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Infer sensitive feature and check accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6736647113306576\n",
      "0.6375424513738808\n",
      "0.6556035813522693\n"
     ]
    }
   ],
   "source": [
    "# get inferred values\n",
    "inferred_train_bb = bb_attack.infer(x_train[attack_train_size:], y_train[attack_train_size:])\n",
    "inferred_test_bb = bb_attack.infer(x_test[attack_test_size:], y_test[attack_test_size:])\n",
    "# check accuracy\n",
    "train_acc = np.sum(inferred_train_bb) / len(inferred_train_bb)\n",
    "test_acc = 1 - (np.sum(inferred_test_bb) / len(inferred_test_bb))\n",
    "acc = (train_acc * len(inferred_train_bb) + test_acc * len(inferred_test_bb)) / (len(inferred_train_bb) + len(inferred_test_bb))\n",
    "print(train_acc)\n",
    "print(test_acc)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Achieves much better results than the rule-based attack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.6501787842669845, 0.6736647113306576)\n"
     ]
    }
   ],
   "source": [
    "# black-box\n",
    "print(calc_precision_recall(np.concatenate((inferred_train_bb, inferred_test_bb)), \n",
    "                            np.concatenate((np.ones(len(inferred_train_bb)), np.zeros(len(inferred_test_bb))))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train neural network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base model accuracy:  0.926\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from art.estimators.classification.pytorch import PyTorchClassifier\n",
    "\n",
    "# reduce size of training set to make attack slightly better\n",
    "train_set_size = 500\n",
    "x_train = x_train[:train_set_size]\n",
    "y_train = y_train[:train_set_size]\n",
    "x_test = x_test[:train_set_size]\n",
    "y_test = y_test[:train_set_size]\n",
    "attack_train_size = int(len(x_train) * attack_train_ratio)\n",
    "attack_test_size = int(len(x_test) * attack_train_ratio)\n",
    "\n",
    "class ModelToAttack(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes, num_features):\n",
    "        super(ModelToAttack, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Sequential(\n",
    "                nn.Linear(num_features, 1024),\n",
    "                nn.Tanh(), )\n",
    "\n",
    "        self.fc2 = nn.Sequential(\n",
    "                nn.Linear(1024, 512),\n",
    "                nn.Tanh(), )\n",
    "\n",
    "        self.fc3 = nn.Sequential(\n",
    "            nn.Linear(512, 256),\n",
    "            nn.Tanh(), )\n",
    "        \n",
    "        self.fc4 = nn.Sequential(\n",
    "            nn.Linear(256, 128),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.fc2(out)\n",
    "        out = self.fc3(out)\n",
    "        out = self.fc4(out)\n",
    "        return self.classifier(out)\n",
    "\n",
    "mlp_model = ModelToAttack(4, 24)\n",
    "mlp_model = torch.nn.DataParallel(mlp_model)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(mlp_model.parameters(), lr=0.01)\n",
    "\n",
    "class NurseryDataset(Dataset):\n",
    "    def __init__(self, x, y=None):\n",
    "        self.x = torch.from_numpy(x.astype(np.float64)).type(torch.FloatTensor)\n",
    "\n",
    "        if y is not None:\n",
    "            self.y = torch.from_numpy(y.astype(np.int8)).type(torch.LongTensor)\n",
    "        else:\n",
    "            self.y = torch.zeros(x.shape[0])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if idx >= len(self.x):\n",
    "            raise IndexError(\"Invalid Index\")\n",
    "\n",
    "        return self.x[idx], self.y[idx]\n",
    "\n",
    "train_set = NurseryDataset(x_train, y_train)\n",
    "train_loader = DataLoader(train_set, batch_size=100, shuffle=True, num_workers=0)\n",
    "\n",
    "for epoch in range(20):\n",
    "    for (input, targets) in train_loader:\n",
    "        input, targets = torch.autograd.Variable(input), torch.autograd.Variable(targets)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = mlp_model(input)\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "mlp_art_model = PyTorchClassifier(model=mlp_model, loss=criterion, optimizer=optimizer, input_shape=(24,), nb_classes=4)\n",
    "\n",
    "pred = np.array([np.argmax(arr) for arr in mlp_art_model.predict(x_test.astype(np.float32))])\n",
    "\n",
    "print('Base model accuracy: ', np.sum(pred == y_test) / len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rule-based attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.998\n",
      "0.07399999999999995\n",
      "0.536\n",
      "(0.5187110187110187, 0.998)\n"
     ]
    }
   ],
   "source": [
    "mlp_attack = MembershipInferenceBlackBoxRuleBased(mlp_art_model)\n",
    "\n",
    "# infer \n",
    "mlp_inferred_train = mlp_attack.infer(x_train.astype(np.float32), y_train)\n",
    "mlp_inferred_test = mlp_attack.infer(x_test.astype(np.float32), y_test)\n",
    "\n",
    "# check accuracy\n",
    "mlp_train_acc = np.sum(mlp_inferred_train) / len(mlp_inferred_train)\n",
    "mlp_test_acc = 1 - (np.sum(mlp_inferred_test) / len(mlp_inferred_test))\n",
    "mlp_acc = (mlp_train_acc * len(mlp_inferred_train) + mlp_test_acc * len(mlp_inferred_test)) / (len(mlp_inferred_train) + len(mlp_inferred_test))\n",
    "print(mlp_train_acc)\n",
    "print(mlp_test_acc)\n",
    "print(mlp_acc)\n",
    "\n",
    "print(calc_precision_recall(np.concatenate((mlp_inferred_train, mlp_inferred_test)), \n",
    "                            np.concatenate((np.ones(len(mlp_inferred_train)), np.zeros(len(mlp_inferred_test))))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Black-box attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.608\n",
      "0.5680000000000001\n",
      "0.588\n",
      "(0.5846153846153846, 0.608)\n"
     ]
    }
   ],
   "source": [
    "mlp_attack_bb = MembershipInferenceBlackBox(mlp_art_model, attack_model_type='rf')\n",
    "\n",
    "# train attack model\n",
    "mlp_attack_bb.fit(x_train[:attack_train_size].astype(np.float32), y_train[:attack_train_size],\n",
    "              x_test[:attack_test_size].astype(np.float32), y_test[:attack_test_size])\n",
    "\n",
    "# infer \n",
    "mlp_inferred_train_bb = mlp_attack_bb.infer(x_train[attack_train_size:].astype(np.float32), y_train[attack_train_size:])\n",
    "mlp_inferred_test_bb = mlp_attack_bb.infer(x_test[attack_test_size:].astype(np.float32), y_test[attack_test_size:])\n",
    "\n",
    "# check accuracy\n",
    "mlp_train_acc_bb = np.sum(mlp_inferred_train_bb) / len(mlp_inferred_train_bb)\n",
    "mlp_test_acc_bb = 1 - (np.sum(mlp_inferred_test_bb) / len(mlp_inferred_test_bb))\n",
    "mlp_acc_bb = (mlp_train_acc_bb * len(mlp_inferred_train_bb) + mlp_test_acc_bb * len(mlp_inferred_test_bb)) / (len(mlp_inferred_train_bb) + len(mlp_inferred_test_bb))\n",
    "print(mlp_train_acc_bb)\n",
    "print(mlp_test_acc_bb)\n",
    "print(mlp_acc_bb)\n",
    "\n",
    "print(calc_precision_recall(np.concatenate((mlp_inferred_train_bb, mlp_inferred_test_bb)), \n",
    "                            np.concatenate((np.ones(len(mlp_inferred_train_bb)), np.zeros(len(mlp_inferred_test_bb))))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the pytorch target model we were able to achieve slightly better than random attack performance, but not as good as for the random forest model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
