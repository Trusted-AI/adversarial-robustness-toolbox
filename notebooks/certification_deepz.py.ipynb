{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cac5c830",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03d16f6",
   "metadata": {},
   "source": [
    "In this notebook we will demonstrate the usage of certification using zonotopes within ART. With deterministic certification methods such as DeepZ we can have a guarantee if a datapoint could have its class changed under a given bound."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785902b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "from art.estimators.certification import deep_z\n",
    "from art.utils import load_mnist, preprocess, to_categorical\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df9e108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We make an example pytorch classifier\n",
    "\n",
    "class MNISTModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MNISTModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1,\n",
    "                               out_channels=32,\n",
    "                               kernel_size=(4, 4),\n",
    "                               stride=(2, 2),\n",
    "                               dilation=(1, 1),\n",
    "                               padding=(0, 0))\n",
    "        self.conv2 = nn.Conv2d(in_channels=32,\n",
    "                               out_channels=32,\n",
    "                               kernel_size=(4, 4),\n",
    "                               stride=(2, 2),\n",
    "                               dilation=(1, 1),\n",
    "                               padding=(0, 0))\n",
    "        self.fc1 = nn.Linear(in_features=800,\n",
    "                             out_features=10)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        if isinstance(x, np.ndarray):\n",
    "            x = torch.from_numpy(x).float().to(device)\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148604f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MNISTModel()\n",
    "opt = optim.Adam(model.parameters(), lr=1e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "(x_train, y_train), (x_test, y_test), min_, max_ = load_mnist()\n",
    "\n",
    "x_test = np.squeeze(x_test)\n",
    "x_test = np.expand_dims(x_test, axis=1)\n",
    "y_test = np.argmax(y_test, axis=1)\n",
    "\n",
    "x_train = np.squeeze(x_train)\n",
    "x_train = np.expand_dims(x_train, axis=1)\n",
    "y_train = np.argmax(y_train, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e240be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model normally\n",
    "\n",
    "def standard_train(model, opt, criterion, x, y, bsize=32, epochs=5):\n",
    "    num_of_batches = int(len(x) / bsize)\n",
    "    for epoch in range(epochs):\n",
    "        # x, y = shuffle(x, y)\n",
    "        loss_list = []\n",
    "        for bnum in range(num_of_batches):\n",
    "            x_batch = np.copy(x[bnum * bsize:(bnum + 1) * bsize])\n",
    "            y_batch = np.copy(y[bnum * bsize:(bnum + 1) * bsize])\n",
    "\n",
    "            x_batch = torch.from_numpy(x_batch).float().to(device)\n",
    "            y_batch = torch.from_numpy(y_batch).type(torch.LongTensor).to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            opt.zero_grad()\n",
    "            outputs = model(x_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            loss_list.append(loss.data)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "        print('End of epoch {} loss {}'.format(epoch, np.mean(loss_list)))\n",
    "    return model\n",
    "\n",
    "model = standard_train(model=model,\n",
    "                       opt=opt,\n",
    "                       criterion=criterion,\n",
    "                       x=x_train,\n",
    "                       y=y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f358bef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets now get the predicions for the MNIST test set and see how well our model is doing.\n",
    "with torch.no_grad():\n",
    "    test_preds = model(torch.from_numpy(x_test).float().to(device))\n",
    "\n",
    "test_preds = np.argmax(test_preds.cpu().detach().numpy(), axis=1)\n",
    "print('Test acc: ', np.mean(test_preds == y_test) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430edde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# But how robust are these predictions? \n",
    "# We can now examine this neural network's certified robustness. \n",
    "# We pass it into PytorchDeepZ. We will get a print out showing which \n",
    "# neural network layers have been registered. There will also be a \n",
    "# warning to tell us that PytorchDeepZ currently infers a reshape when \n",
    "# a neural network goes from using convolutional to dense layers. \n",
    "# This will cover the majority of use cases, however, if not then the \n",
    "# certification layers in art.estimators.certification.deepz.deep_z.py \n",
    "# can be used to directly build a certified model structure.\n",
    "\n",
    "zonotope_model = deep_z.PytorchDeepZ(model=model, \n",
    "                                     clip_values=(0, 1), \n",
    "                                     loss=nn.CrossEntropyLoss(), \n",
    "                                     input_shape=(1, 28, 28), \n",
    "                                     nb_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5749a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets now see how robust our model is!\n",
    "# First we need to define what bound we need to check. \n",
    "# Here let's check for L infinity robustness with small bound of 0.01\n",
    "\n",
    "bound = 0.1\n",
    "num_certified = 0\n",
    "num_correct = 0\n",
    "\n",
    "# lets now loop over the data to check its certified robustness:\n",
    "# we need to consider a single sample at a time as due to memory and compute footprints batching is not supported.\n",
    "# In this demo we will look at the first 50 samples of the MNIST test data.\n",
    "original_x = np.copy(x_test)\n",
    "for i, (sample, pred, label) in enumerate(zip(x_test[:50], test_preds[:50], y_test[:50])):\n",
    "    \n",
    "    # we make the matrix representing the allowable perturbations. \n",
    "    # we have 28*28 features and each one can be manipulated independently requiring a different row.\n",
    "    # hence a 784*784 matrix.\n",
    "    eps_bound = np.eye(784) * bound\n",
    "    \n",
    "    # we then need to adjust the raw data with the eps bounds to take into account\n",
    "    # the allowable range of 0 - 1 for pixel data.\n",
    "    # We provide a simple function to do this preprocessing for image data.\n",
    "    # However if your use case is not supported then a custom pre-processor function will need to be written.\n",
    "    sample, eps_bound = zonotope_model.pre_process(cent=sample, \n",
    "                                                   eps=eps_bound)\n",
    "    sample = np.expand_dims(sample, axis=0)\n",
    "\n",
    "    # We pass the data sample and the eps bound to the certifier along with the prediction that was made\n",
    "    # for the datapoint. \n",
    "    # A boolean is returned signifying if it can have its class changed under the given bound.\n",
    "    is_certified = zonotope_model.certify(cent=sample,\n",
    "                                          eps=eps_bound,\n",
    "                                          prediction=pred)\n",
    "    \n",
    "    if pred == label:\n",
    "        num_correct +=1\n",
    "        if is_certified:\n",
    "            num_certified +=1 \n",
    "    \n",
    "    print('Classified Correct {}/{} and also certified {}/{}'.format(num_correct, i, num_certified, i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b858fc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can then compare this to the empirical PGD performance\n",
    "\n",
    "from art.estimators.classification import PyTorchClassifier\n",
    "from art.attacks.evasion.projected_gradient_descent.projected_gradient_descent import ProjectedGradientDescent\n",
    "\n",
    "classifier = PyTorchClassifier(\n",
    "    model=model,\n",
    "    clip_values=(0.0, 1.0),\n",
    "    loss=criterion,\n",
    "    optimizer=opt,\n",
    "    input_shape=(1, 28, 28),\n",
    "    nb_classes=10,\n",
    ")\n",
    "\n",
    "attack = ProjectedGradientDescent(classifier, eps=0.1, eps_step=0.01, verbose=False)\n",
    "x_train_adv = attack.generate(x_test[:50].astype('float32'))\n",
    "y_adv_pred = classifier.predict(torch.from_numpy(x_train_adv).float().to(device))\n",
    "y_adv_pred = np.argmax(y_adv_pred, axis=1)\n",
    "print('Test acc: ', np.mean(y_adv_pred == y_test[:50]) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f60d178",
   "metadata": {},
   "source": [
    "we can see that the empirical test accuracy is much higher than the certifiable performance. This is because with certifiable techniques we will be providing a lower bound on the performance: there may well be datapoints that the certifier says are unsafe, but in fact cannot have their class changed."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
