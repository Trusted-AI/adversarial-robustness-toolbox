# Autogenerated by onnx-pytorch.

import glob
import os

import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F


class Model(nn.Module):
  def __init__(self):
    super(Model, self).__init__()
    self.__vars = nn.ParameterDict()
    for b in glob.glob(
        os.path.join(os.path.dirname(__file__), "variables", "*.npy")):
      v = torch.from_numpy(np.load(b))
      requires_grad = v.dtype.is_floating_point or v.dtype.is_complex
      self.__vars[os.path.basename(b)[:-4]] = nn.Parameter(
          torch.from_numpy(np.load(b)), requires_grad=requires_grad)
    self.n_n_conv2d_1 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 16, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 3, 'bias': True})
    self.n_n_conv2d_1.weight.data = self.__vars["t_conv2d_1_W_new"]
    self.n_n_conv2d_1.bias.data = self.__vars["t_conv2d_1_B_new"]
    self.n_n_conv2d_2 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 16, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 16, 'bias': True})
    self.n_n_conv2d_2.weight.data = self.__vars["t_conv2d_2_W_new"]
    self.n_n_conv2d_2.bias.data = self.__vars["t_conv2d_2_B_new"]
    self.n_n_conv2d_3 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 16, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 16, 'bias': True})
    self.n_n_conv2d_3.weight.data = self.__vars["t_conv2d_3_3_kernel_0"]
    self.n_n_conv2d_3.bias.data = self.__vars["t_conv2d_3_3_bias_0"]
    self.n_n_batch_normalization_3 = nn.BatchNorm2d(**{'num_features': 16, 'eps': 9.999999974752427e-07, 'momentum': 0.9900000095367432})
    self.n_n_batch_normalization_3.weight.data = self.__vars["t_scale30"]
    self.n_n_batch_normalization_3.bias.data = self.__vars["t_bias30"]
    self.n_n_batch_normalization_3.running_mean.data = self.__vars["t_mean30"]
    self.n_n_batch_normalization_3.running_var.data = self.__vars["t_var30"]
    self.n_n_conv2d_4 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 16, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 16, 'bias': True})
    self.n_n_conv2d_4.weight.data = self.__vars["t_conv2d_4_W_new"]
    self.n_n_conv2d_4.bias.data = self.__vars["t_conv2d_4_B_new"]
    self.n_n_conv2d_5 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 16, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 16, 'bias': True})
    self.n_n_conv2d_5.weight.data = self.__vars["t_conv2d_5_3_kernel_0"]
    self.n_n_conv2d_5.bias.data = self.__vars["t_conv2d_5_3_bias_0"]
    self.n_n_batch_normalization_5 = nn.BatchNorm2d(**{'num_features': 16, 'eps': 9.999999974752427e-07, 'momentum': 0.9900000095367432})
    self.n_n_batch_normalization_5.weight.data = self.__vars["t_scale29"]
    self.n_n_batch_normalization_5.bias.data = self.__vars["t_bias29"]
    self.n_n_batch_normalization_5.running_mean.data = self.__vars["t_mean29"]
    self.n_n_batch_normalization_5.running_var.data = self.__vars["t_var29"]
    self.n_n_conv2d_6 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 16, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 16, 'bias': True})
    self.n_n_conv2d_6.weight.data = self.__vars["t_conv2d_6_W_new"]
    self.n_n_conv2d_6.bias.data = self.__vars["t_conv2d_6_B_new"]
    self.n_n_conv2d_7 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 16, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 16, 'bias': True})
    self.n_n_conv2d_7.weight.data = self.__vars["t_conv2d_7_3_kernel_0"]
    self.n_n_conv2d_7.bias.data = self.__vars["t_conv2d_7_3_bias_0"]
    self.n_n_batch_normalization_7 = nn.BatchNorm2d(**{'num_features': 16, 'eps': 9.999999974752427e-07, 'momentum': 0.9900000095367432})
    self.n_n_batch_normalization_7.weight.data = self.__vars["t_scale28"]
    self.n_n_batch_normalization_7.bias.data = self.__vars["t_bias28"]
    self.n_n_batch_normalization_7.running_mean.data = self.__vars["t_mean28"]
    self.n_n_batch_normalization_7.running_var.data = self.__vars["t_var28"]
    self.n_n_conv2d_8 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 16, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 16, 'bias': True})
    self.n_n_conv2d_8.weight.data = self.__vars["t_conv2d_8_W_new"]
    self.n_n_conv2d_8.bias.data = self.__vars["t_conv2d_8_B_new"]
    self.n_n_conv2d_9 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 16, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 16, 'bias': True})
    self.n_n_conv2d_9.weight.data = self.__vars["t_conv2d_9_3_kernel_0"]
    self.n_n_conv2d_9.bias.data = self.__vars["t_conv2d_9_3_bias_0"]
    self.n_n_batch_normalization_9 = nn.BatchNorm2d(**{'num_features': 16, 'eps': 9.999999974752427e-07, 'momentum': 0.9900000095367432})
    self.n_n_batch_normalization_9.weight.data = self.__vars["t_scale26"]
    self.n_n_batch_normalization_9.bias.data = self.__vars["t_bias26"]
    self.n_n_batch_normalization_9.running_mean.data = self.__vars["t_mean26"]
    self.n_n_batch_normalization_9.running_var.data = self.__vars["t_var26"]
    self.n_n_conv2d_10 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 16, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 16, 'bias': True})
    self.n_n_conv2d_10.weight.data = self.__vars["t_conv2d_10_W_new"]
    self.n_n_conv2d_10.bias.data = self.__vars["t_conv2d_10_B_new"]
    self.n_n_conv2d_11 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 16, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 16, 'bias': True})
    self.n_n_conv2d_11.weight.data = self.__vars["t_conv2d_11_3_kernel_0"]
    self.n_n_conv2d_11.bias.data = self.__vars["t_conv2d_11_3_bias_0"]
    self.n_n_conv2d_14 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 32, 'padding': 0, 'kernel_size': (1, 1), 'stride': [2, 2], 'in_channels': 16, 'bias': True})
    self.n_n_conv2d_14.weight.data = self.__vars["t_conv2d_14_3_kernel_0"]
    self.n_n_conv2d_14.bias.data = self.__vars["t_conv2d_14_3_bias_0"]
    self.n_n_batch_normalization_11 = nn.BatchNorm2d(**{'num_features': 16, 'eps': 9.999999974752427e-07, 'momentum': 0.9900000095367432})
    self.n_n_batch_normalization_11.weight.data = self.__vars["t_scale22"]
    self.n_n_batch_normalization_11.bias.data = self.__vars["t_bias22"]
    self.n_n_batch_normalization_11.running_mean.data = self.__vars["t_mean22"]
    self.n_n_batch_normalization_11.running_var.data = self.__vars["t_var22"]
    self.n_n_conv2d_12 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 32, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [2, 2], 'in_channels': 16, 'bias': True})
    self.n_n_conv2d_12.weight.data = self.__vars["t_conv2d_12_W_new"]
    self.n_n_conv2d_12.bias.data = self.__vars["t_conv2d_12_B_new"]
    self.n_n_conv2d_13 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 32, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 32, 'bias': True})
    self.n_n_conv2d_13.weight.data = self.__vars["t_conv2d_13_3_kernel_0"]
    self.n_n_conv2d_13.bias.data = self.__vars["t_conv2d_13_3_bias_0"]
    self.n_n_batch_normalization_13 = nn.BatchNorm2d(**{'num_features': 32, 'eps': 9.999999974752427e-07, 'momentum': 0.9900000095367432})
    self.n_n_batch_normalization_13.weight.data = self.__vars["t_scale20"]
    self.n_n_batch_normalization_13.bias.data = self.__vars["t_bias20"]
    self.n_n_batch_normalization_13.running_mean.data = self.__vars["t_mean20"]
    self.n_n_batch_normalization_13.running_var.data = self.__vars["t_var20"]
    self.n_n_conv2d_15 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 32, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 32, 'bias': True})
    self.n_n_conv2d_15.weight.data = self.__vars["t_conv2d_15_W_new"]
    self.n_n_conv2d_15.bias.data = self.__vars["t_conv2d_15_B_new"]
    self.n_n_conv2d_16 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 32, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 32, 'bias': True})
    self.n_n_conv2d_16.weight.data = self.__vars["t_conv2d_16_3_kernel_0"]
    self.n_n_conv2d_16.bias.data = self.__vars["t_conv2d_16_3_bias_0"]
    self.n_n_batch_normalization_15 = nn.BatchNorm2d(**{'num_features': 32, 'eps': 9.999999974752427e-07, 'momentum': 0.9900000095367432})
    self.n_n_batch_normalization_15.weight.data = self.__vars["t_scale18"]
    self.n_n_batch_normalization_15.bias.data = self.__vars["t_bias18"]
    self.n_n_batch_normalization_15.running_mean.data = self.__vars["t_mean18"]
    self.n_n_batch_normalization_15.running_var.data = self.__vars["t_var18"]
    self.n_n_conv2d_17 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 32, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 32, 'bias': True})
    self.n_n_conv2d_17.weight.data = self.__vars["t_conv2d_17_W_new"]
    self.n_n_conv2d_17.bias.data = self.__vars["t_conv2d_17_B_new"]
    self.n_n_conv2d_18 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 32, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 32, 'bias': True})
    self.n_n_conv2d_18.weight.data = self.__vars["t_conv2d_18_3_kernel_0"]
    self.n_n_conv2d_18.bias.data = self.__vars["t_conv2d_18_3_bias_0"]
    self.n_n_batch_normalization_17 = nn.BatchNorm2d(**{'num_features': 32, 'eps': 9.999999974752427e-07, 'momentum': 0.9900000095367432})
    self.n_n_batch_normalization_17.weight.data = self.__vars["t_scale17"]
    self.n_n_batch_normalization_17.bias.data = self.__vars["t_bias17"]
    self.n_n_batch_normalization_17.running_mean.data = self.__vars["t_mean17"]
    self.n_n_batch_normalization_17.running_var.data = self.__vars["t_var17"]
    self.n_n_conv2d_19 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 32, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 32, 'bias': True})
    self.n_n_conv2d_19.weight.data = self.__vars["t_conv2d_19_W_new"]
    self.n_n_conv2d_19.bias.data = self.__vars["t_conv2d_19_B_new"]
    self.n_n_conv2d_20 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 32, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 32, 'bias': True})
    self.n_n_conv2d_20.weight.data = self.__vars["t_conv2d_20_3_kernel_0"]
    self.n_n_conv2d_20.bias.data = self.__vars["t_conv2d_20_3_bias_0"]
    self.n_n_batch_normalization_19 = nn.BatchNorm2d(**{'num_features': 32, 'eps': 9.999999974752427e-07, 'momentum': 0.9900000095367432})
    self.n_n_batch_normalization_19.weight.data = self.__vars["t_scale15"]
    self.n_n_batch_normalization_19.bias.data = self.__vars["t_bias15"]
    self.n_n_batch_normalization_19.running_mean.data = self.__vars["t_mean15"]
    self.n_n_batch_normalization_19.running_var.data = self.__vars["t_var15"]
    self.n_n_conv2d_21 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 32, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 32, 'bias': True})
    self.n_n_conv2d_21.weight.data = self.__vars["t_conv2d_21_W_new"]
    self.n_n_conv2d_21.bias.data = self.__vars["t_conv2d_21_B_new"]
    self.n_n_conv2d_22 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 32, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 32, 'bias': True})
    self.n_n_conv2d_22.weight.data = self.__vars["t_conv2d_22_3_kernel_0"]
    self.n_n_conv2d_22.bias.data = self.__vars["t_conv2d_22_3_bias_0"]
    self.n_n_conv2d_25 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 64, 'padding': 0, 'kernel_size': (1, 1), 'stride': [2, 2], 'in_channels': 32, 'bias': True})
    self.n_n_conv2d_25.weight.data = self.__vars["t_conv2d_25_3_kernel_0"]
    self.n_n_conv2d_25.bias.data = self.__vars["t_conv2d_25_3_bias_0"]
    self.n_n_batch_normalization_21 = nn.BatchNorm2d(**{'num_features': 32, 'eps': 9.999999974752427e-07, 'momentum': 0.9900000095367432})
    self.n_n_batch_normalization_21.weight.data = self.__vars["t_scale12"]
    self.n_n_batch_normalization_21.bias.data = self.__vars["t_bias12"]
    self.n_n_batch_normalization_21.running_mean.data = self.__vars["t_mean12"]
    self.n_n_batch_normalization_21.running_var.data = self.__vars["t_var12"]
    self.n_n_conv2d_23 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 64, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [2, 2], 'in_channels': 32, 'bias': True})
    self.n_n_conv2d_23.weight.data = self.__vars["t_conv2d_23_W_new"]
    self.n_n_conv2d_23.bias.data = self.__vars["t_conv2d_23_B_new"]
    self.n_n_conv2d_24 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 64, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 64, 'bias': True})
    self.n_n_conv2d_24.weight.data = self.__vars["t_conv2d_24_3_kernel_0"]
    self.n_n_conv2d_24.bias.data = self.__vars["t_conv2d_24_3_bias_0"]
    self.n_n_batch_normalization_23 = nn.BatchNorm2d(**{'num_features': 64, 'eps': 9.999999974752427e-07, 'momentum': 0.9900000095367432})
    self.n_n_batch_normalization_23.weight.data = self.__vars["t_scale10"]
    self.n_n_batch_normalization_23.bias.data = self.__vars["t_bias10"]
    self.n_n_batch_normalization_23.running_mean.data = self.__vars["t_mean10"]
    self.n_n_batch_normalization_23.running_var.data = self.__vars["t_var10"]
    self.n_n_conv2d_26 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 64, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 64, 'bias': True})
    self.n_n_conv2d_26.weight.data = self.__vars["t_conv2d_26_W_new"]
    self.n_n_conv2d_26.bias.data = self.__vars["t_conv2d_26_B_new"]
    self.n_n_conv2d_27 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 64, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 64, 'bias': True})
    self.n_n_conv2d_27.weight.data = self.__vars["t_conv2d_27_3_kernel_0"]
    self.n_n_conv2d_27.bias.data = self.__vars["t_conv2d_27_3_bias_0"]
    self.n_n_batch_normalization_25 = nn.BatchNorm2d(**{'num_features': 64, 'eps': 9.999999974752427e-07, 'momentum': 0.9900000095367432})
    self.n_n_batch_normalization_25.weight.data = self.__vars["t_scale8"]
    self.n_n_batch_normalization_25.bias.data = self.__vars["t_bias8"]
    self.n_n_batch_normalization_25.running_mean.data = self.__vars["t_mean8"]
    self.n_n_batch_normalization_25.running_var.data = self.__vars["t_var8"]
    self.n_n_conv2d_28 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 64, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 64, 'bias': True})
    self.n_n_conv2d_28.weight.data = self.__vars["t_conv2d_28_W_new"]
    self.n_n_conv2d_28.bias.data = self.__vars["t_conv2d_28_B_new"]
    self.n_n_conv2d_29 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 64, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 64, 'bias': True})
    self.n_n_conv2d_29.weight.data = self.__vars["t_conv2d_29_3_kernel_0"]
    self.n_n_conv2d_29.bias.data = self.__vars["t_conv2d_29_3_bias_0"]
    self.n_n_batch_normalization_27 = nn.BatchNorm2d(**{'num_features': 64, 'eps': 9.999999974752427e-07, 'momentum': 0.9900000095367432})
    self.n_n_batch_normalization_27.weight.data = self.__vars["t_scale7"]
    self.n_n_batch_normalization_27.bias.data = self.__vars["t_bias7"]
    self.n_n_batch_normalization_27.running_mean.data = self.__vars["t_mean7"]
    self.n_n_batch_normalization_27.running_var.data = self.__vars["t_var7"]
    self.n_n_conv2d_30 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 64, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 64, 'bias': True})
    self.n_n_conv2d_30.weight.data = self.__vars["t_conv2d_30_W_new"]
    self.n_n_conv2d_30.bias.data = self.__vars["t_conv2d_30_B_new"]
    self.n_n_conv2d_31 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 64, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 64, 'bias': True})
    self.n_n_conv2d_31.weight.data = self.__vars["t_conv2d_31_3_kernel_0"]
    self.n_n_conv2d_31.bias.data = self.__vars["t_conv2d_31_3_bias_0"]
    self.n_n_batch_normalization_29 = nn.BatchNorm2d(**{'num_features': 64, 'eps': 9.999999974752427e-07, 'momentum': 0.9900000095367432})
    self.n_n_batch_normalization_29.weight.data = self.__vars["t_scale5"]
    self.n_n_batch_normalization_29.bias.data = self.__vars["t_bias5"]
    self.n_n_batch_normalization_29.running_mean.data = self.__vars["t_mean5"]
    self.n_n_batch_normalization_29.running_var.data = self.__vars["t_var5"]
    self.n_n_conv2d_32 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 64, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 64, 'bias': True})
    self.n_n_conv2d_32.weight.data = self.__vars["t_conv2d_32_W_new"]
    self.n_n_conv2d_32.bias.data = self.__vars["t_conv2d_32_B_new"]
    self.n_n_conv2d_33 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 64, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 64, 'bias': True})
    self.n_n_conv2d_33.weight.data = self.__vars["t_conv2d_33_3_kernel_0"]
    self.n_n_conv2d_33.bias.data = self.__vars["t_conv2d_33_3_bias_0"]
    self.n_n_batch_normalization_31 = nn.BatchNorm2d(**{'num_features': 64, 'eps': 9.999999974752427e-07, 'momentum': 0.9900000095367432})
    self.n_n_batch_normalization_31.weight.data = self.__vars["t_scale"]
    self.n_n_batch_normalization_31.bias.data = self.__vars["t_bias"]
    self.n_n_batch_normalization_31.running_mean.data = self.__vars["t_mean"]
    self.n_n_batch_normalization_31.running_var.data = self.__vars["t_var"]
    self.n_n_dropout_1_3_cond_Identity_0_pooling = nn.AvgPool2d(**{'kernel_size': [8, 8], 'ceil_mode': False, 'stride': [1, 1], 'count_include_pad': False})
    self.n_n_flatten_1 = nn.Flatten(**{'start_dim': 1})

  def forward(self, *inputs):
    t_input_1, = inputs
    t_adjusted_input30 = t_input_1.permute(*[0, 3, 1, 2])
    t_convolution_output30 = self.n_n_conv2d_1(t_adjusted_input30)
    t_activation_1_3_Relu_0 = F.relu(t_convolution_output30)
    t_convolution_output32 = self.n_n_conv2d_2(t_activation_1_3_Relu_0)
    t_activation_2_3_Relu_0 = F.relu(t_convolution_output32)
    t_convolution_output27 = self.n_n_conv2d_3(t_activation_2_3_Relu_0)
    t_add_1_3_add_0 = t_activation_1_3_Relu_0 + t_convolution_output27
    t_batch_norm_output_buffer30 = self.n_n_batch_normalization_3(t_add_1_3_add_0)
    t_activation_3_3_Relu_0 = F.relu(t_batch_norm_output_buffer30)
    t_convolution_output31 = self.n_n_conv2d_4(t_activation_3_3_Relu_0)
    t_activation_4_3_Relu_0 = F.relu(t_convolution_output31)
    t_convolution_output25 = self.n_n_conv2d_5(t_activation_4_3_Relu_0)
    t_add_2_3_add_0 = t_add_1_3_add_0 + t_convolution_output25
    t_batch_norm_output_buffer29 = self.n_n_batch_normalization_5(t_add_2_3_add_0)
    t_activation_5_3_Relu_0 = F.relu(t_batch_norm_output_buffer29)
    t_convolution_output29 = self.n_n_conv2d_6(t_activation_5_3_Relu_0)
    t_activation_6_3_Relu_0 = F.relu(t_convolution_output29)
    t_convolution_output24 = self.n_n_conv2d_7(t_activation_6_3_Relu_0)
    t_add_3_3_add_0 = t_add_2_3_add_0 + t_convolution_output24
    t_batch_norm_output_buffer28 = self.n_n_batch_normalization_7(t_add_3_3_add_0)
    t_activation_7_3_Relu_0 = F.relu(t_batch_norm_output_buffer28)
    t_convolution_output28 = self.n_n_conv2d_8(t_activation_7_3_Relu_0)
    t_activation_8_3_Relu_0 = F.relu(t_convolution_output28)
    t_convolution_output22 = self.n_n_conv2d_9(t_activation_8_3_Relu_0)
    t_add_4_3_add_0 = t_add_3_3_add_0 + t_convolution_output22
    t_batch_norm_output_buffer26 = self.n_n_batch_normalization_9(t_add_4_3_add_0)
    t_activation_9_3_Relu_0 = F.relu(t_batch_norm_output_buffer26)
    t_convolution_output26 = self.n_n_conv2d_10(t_activation_9_3_Relu_0)
    t_activation_10_3_Relu_0 = F.relu(t_convolution_output26)
    t_convolution_output20 = self.n_n_conv2d_11(t_activation_10_3_Relu_0)
    t_add_5_3_add_0 = t_add_4_3_add_0 + t_convolution_output20
    t_convolution_output16 = self.n_n_conv2d_14(t_add_5_3_add_0)
    t_batch_norm_output_buffer22 = self.n_n_batch_normalization_11(t_add_5_3_add_0)
    t_activation_11_3_Relu_0 = F.relu(t_batch_norm_output_buffer22)
    t_convolution_output23 = self.n_n_conv2d_12(t_activation_11_3_Relu_0)
    t_activation_12_3_Relu_0 = F.relu(t_convolution_output23)
    t_convolution_output17 = self.n_n_conv2d_13(t_activation_12_3_Relu_0)
    t_add_6_3_add_0 = t_convolution_output16 + t_convolution_output17
    t_batch_norm_output_buffer20 = self.n_n_batch_normalization_13(t_add_6_3_add_0)
    t_activation_13_3_Relu_0 = F.relu(t_batch_norm_output_buffer20)
    t_convolution_output21 = self.n_n_conv2d_15(t_activation_13_3_Relu_0)
    t_activation_14_3_Relu_0 = F.relu(t_convolution_output21)
    t_convolution_output14 = self.n_n_conv2d_16(t_activation_14_3_Relu_0)
    t_add_7_3_add_0 = t_add_6_3_add_0 + t_convolution_output14
    t_batch_norm_output_buffer18 = self.n_n_batch_normalization_15(t_add_7_3_add_0)
    t_activation_15_3_Relu_0 = F.relu(t_batch_norm_output_buffer18)
    t_convolution_output19 = self.n_n_conv2d_17(t_activation_15_3_Relu_0)
    t_activation_16_3_Relu_0 = F.relu(t_convolution_output19)
    t_convolution_output13 = self.n_n_conv2d_18(t_activation_16_3_Relu_0)
    t_add_8_3_add_0 = t_add_7_3_add_0 + t_convolution_output13
    t_batch_norm_output_buffer17 = self.n_n_batch_normalization_17(t_add_8_3_add_0)
    t_activation_17_3_Relu_0 = F.relu(t_batch_norm_output_buffer17)
    t_convolution_output18 = self.n_n_conv2d_19(t_activation_17_3_Relu_0)
    t_activation_18_3_Relu_0 = F.relu(t_convolution_output18)
    t_convolution_output11 = self.n_n_conv2d_20(t_activation_18_3_Relu_0)
    t_add_9_3_add_0 = t_add_8_3_add_0 + t_convolution_output11
    t_batch_norm_output_buffer15 = self.n_n_batch_normalization_19(t_add_9_3_add_0)
    t_activation_19_3_Relu_0 = F.relu(t_batch_norm_output_buffer15)
    t_convolution_output15 = self.n_n_conv2d_21(t_activation_19_3_Relu_0)
    t_activation_20_3_Relu_0 = F.relu(t_convolution_output15)
    t_convolution_output9 = self.n_n_conv2d_22(t_activation_20_3_Relu_0)
    t_add_10_3_add_0 = t_add_9_3_add_0 + t_convolution_output9
    t_convolution_output5 = self.n_n_conv2d_25(t_add_10_3_add_0)
    t_batch_norm_output_buffer12 = self.n_n_batch_normalization_21(t_add_10_3_add_0)
    t_activation_21_3_Relu_0 = F.relu(t_batch_norm_output_buffer12)
    t_convolution_output12 = self.n_n_conv2d_23(t_activation_21_3_Relu_0)
    t_activation_22_3_Relu_0 = F.relu(t_convolution_output12)
    t_convolution_output6 = self.n_n_conv2d_24(t_activation_22_3_Relu_0)
    t_add_11_3_add_0 = t_convolution_output5 + t_convolution_output6
    t_batch_norm_output_buffer10 = self.n_n_batch_normalization_23(t_add_11_3_add_0)
    t_activation_23_3_Relu_0 = F.relu(t_batch_norm_output_buffer10)
    t_convolution_output10 = self.n_n_conv2d_26(t_activation_23_3_Relu_0)
    t_activation_24_3_Relu_0 = F.relu(t_convolution_output10)
    t_convolution_output3 = self.n_n_conv2d_27(t_activation_24_3_Relu_0)
    t_add_12_3_add_0 = t_add_11_3_add_0 + t_convolution_output3
    t_batch_norm_output_buffer8 = self.n_n_batch_normalization_25(t_add_12_3_add_0)
    t_activation_25_3_Relu_0 = F.relu(t_batch_norm_output_buffer8)
    t_convolution_output8 = self.n_n_conv2d_28(t_activation_25_3_Relu_0)
    t_activation_26_3_Relu_0 = F.relu(t_convolution_output8)
    t_convolution_output2 = self.n_n_conv2d_29(t_activation_26_3_Relu_0)
    t_add_13_3_add_0 = t_add_12_3_add_0 + t_convolution_output2
    t_batch_norm_output_buffer7 = self.n_n_batch_normalization_27(t_add_13_3_add_0)
    t_activation_27_3_Relu_0 = F.relu(t_batch_norm_output_buffer7)
    t_convolution_output7 = self.n_n_conv2d_30(t_activation_27_3_Relu_0)
    t_activation_28_3_Relu_0 = F.relu(t_convolution_output7)
    t_convolution_output1 = self.n_n_conv2d_31(t_activation_28_3_Relu_0)
    t_add_14_3_add_0 = t_add_13_3_add_0 + t_convolution_output1
    t_batch_norm_output_buffer5 = self.n_n_batch_normalization_29(t_add_14_3_add_0)
    t_activation_29_3_Relu_0 = F.relu(t_batch_norm_output_buffer5)
    t_convolution_output4 = self.n_n_conv2d_32(t_activation_29_3_Relu_0)
    t_activation_30_3_Relu_0 = F.relu(t_convolution_output4)
    t_convolution_output = self.n_n_conv2d_33(t_activation_30_3_Relu_0)
    t_add_15_3_add_0 = t_add_14_3_add_0 + t_convolution_output
    t_batch_norm_output_buffer = self.n_n_batch_normalization_31(t_add_15_3_add_0)
    t_activation_31_3_Relu_0 = F.relu(t_batch_norm_output_buffer)
    t_dropout_1_3_cond_Identity_0_pooling0 = self.n_n_dropout_1_3_cond_Identity_0_pooling(t_activation_31_3_Relu_0)[:, :]
    t_dropout_1_3_cond_Identity_0_transpose0 = t_dropout_1_3_cond_Identity_0_pooling0.permute(*[0, 3, 1, 2])
    t_flatten_1_3_Reshape_0 = self.n_n_flatten_1(t_dropout_1_3_cond_Identity_0_transpose0)
    t_classifier0 = torch.matmul(t_flatten_1_3_Reshape_0, self.__vars["t_classifier_3_kernel_0"])
    t_biased_tensor_name = t_classifier0 + self.__vars["t_classifier_3_bias_0"]
    t_classifier = F.softmax(t_biased_tensor_name, **{'dim': -1})
    return t_classifier


@torch.no_grad()
def test_run_model(inputs=[torch.from_numpy(np.random.randn(*[1, 32, 32, 3]).astype(np.float32))]):
  model = Model()
  model.eval()
  print(model)
  rs = model(*inputs)
  print(rs)
  return rs
