{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/synergit/adversarial-robustness-toolbox/blob/development_issue_1331/sign_opt_CIFAR10_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prTsZEeiBg__"
      },
      "source": [
        "Reference: http://home.mit.bme.hu/~hadhazi/Oktatas/NN18/dem3/html_demo/CIFAR-10Demo.html"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# mount google drive https://medium.com/@ml_kid/how-to-save-our-model-to-google-drive-and-reuse-it-2c1028058cb2\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3rMMis9BScKw",
        "outputId": "2a3a647d-c75d-40bc-f057-984f5be495eb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/gdrive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nxNzNjB5TSe8",
        "outputId": "756becaa-d77d-4a64-ed5b-b68cf09cae10"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H29fOnbuHwao",
        "outputId": "659de923-ffa1-4580-c84a-d43e7eade0ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting adversarial-robustness-toolbox\n",
            "  Downloading adversarial_robustness_toolbox-1.10.0-py3-none-any.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from adversarial-robustness-toolbox) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn<1.1.0,>=0.22.2 in /usr/local/lib/python3.7/dist-packages (from adversarial-robustness-toolbox) (1.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from adversarial-robustness-toolbox) (4.63.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from adversarial-robustness-toolbox) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from adversarial-robustness-toolbox) (57.4.0)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.7/dist-packages (from adversarial-robustness-toolbox) (1.21.5)\n",
            "Collecting numba>=0.53.1\n",
            "  Downloading numba-0.55.1-1-cp37-cp37m-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 37.0 MB/s \n",
            "\u001b[?25hCollecting llvmlite<0.39,>=0.38.0rc1\n",
            "  Downloading llvmlite-0.38.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 34.5 MB 13 kB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn<1.1.0,>=0.22.2->adversarial-robustness-toolbox) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn<1.1.0,>=0.22.2->adversarial-robustness-toolbox) (3.1.0)\n",
            "Installing collected packages: llvmlite, numba, adversarial-robustness-toolbox\n",
            "  Attempting uninstall: llvmlite\n",
            "    Found existing installation: llvmlite 0.34.0\n",
            "    Uninstalling llvmlite-0.34.0:\n",
            "      Successfully uninstalled llvmlite-0.34.0\n",
            "  Attempting uninstall: numba\n",
            "    Found existing installation: numba 0.51.2\n",
            "    Uninstalling numba-0.51.2:\n",
            "      Successfully uninstalled numba-0.51.2\n",
            "Successfully installed adversarial-robustness-toolbox-1.10.0 llvmlite-0.38.0 numba-0.55.1\n"
          ]
        }
      ],
      "source": [
        "!pip install adversarial-robustness-toolbox"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "oYZ4HsBFQicq"
      },
      "outputs": [],
      "source": [
        "# art.utils only loads first 5000 training and 500 test data\n",
        "from art.utils import load_cifar10\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def load_data(raw_image, length):\n",
        "  (x_train, y_train), (x_test, y_test), min_, max_ = load_cifar10(raw=raw_image)#load_dataset(str(\"cifar10\"))\n",
        "  # x_train.shape (5000, 32, 32, 3)\n",
        "  # y_train.shape (5000, 10)\n",
        "  x_train, y_train = x_train[:length], y_train[:length]\n",
        "  # x_test.shape (500, 32, 32, 3)\n",
        "  # y_test.shape (500, 10)\n",
        "  x_test, y_test = x_test[:int(length/10)], y_test[:int(length/10)]\n",
        "  print(x_train[0].shape)\n",
        "  \n",
        "  imshow_CIFAR10(raw_image, x_train, y_train, 5)\n",
        "  \n",
        "  return (x_train, y_train), (x_test, y_test), min_, max_\n",
        "\n",
        "\n",
        "def imshow_CIFAR10(raw_image, x_train, y_train, length):\n",
        "  if raw_image:\n",
        "    cifar_classes = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "    print('Example training images and their labels: ' + str([x[0] for x in y_train[0:length]])) \n",
        "    print('Corresponding classes for the labels: ' + str([cifar_classes[x[0]] for x in y_train[0:length]]))\n",
        "\n",
        "    f, axarr = plt.subplots(1, length)\n",
        "    f.set_size_inches(16, 6)\n",
        "\n",
        "    for i in range(5):\n",
        "        img = x_train[i]\n",
        "        axarr[i].imshow(img)\n",
        "    plt.show()\n",
        "  else:\n",
        "    print('change `raw_image` to be True for showing images')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "QOaJ5odgcPia"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "NCiE72pOP12m"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchsummary import summary\n",
        "\n",
        "# Define the neural network model, return logits instead of activation in forward method\n",
        "###\n",
        "# define the network as https://arxiv.org/pdf/1608.04644.pdf, table 1\n",
        "###\n",
        "class Net_table1_CIFAR10(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net_table1_CIFAR10, self).__init__()\n",
        "        self.conv_1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride=1)\n",
        "        self.conv_2 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1)\n",
        "        self.conv_3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1)\n",
        "        self.conv_4 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1)\n",
        "        # https://discuss.pytorch.org/t/calculation-for-the-input-to-the-fully-connected-layer/82774/11\n",
        "        # x.shape: torch.Size([2, 128, 5, 5]) so, 128*5*5\n",
        "        self.fc_1 = nn.Linear(in_features= 3200, out_features=256) \n",
        "        self.fc_2 = nn.Linear(in_features=256, out_features=10)\n",
        "        \n",
        "    # https://github.com/Carco-git/CW_Attack_on_MNIST/blob/master/MNIST_Model.py\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv_1(x))\n",
        "        x = F.relu(self.conv_2(x))\n",
        "        x = F.max_pool2d(x, 2, 2)\n",
        "        x = F.relu(self.conv_3(x))\n",
        "        x = F.relu(self.conv_4(x))\n",
        "        x = F.max_pool2d(x, 2, 2)\n",
        "        # print(x.shape) # torch.Size([2, 128, 5, 5])\n",
        "        x = x.view(-1, 3200)\n",
        "        \n",
        "        x = F.relu(self.fc_1(x))\n",
        "        x = F.dropout(x, p=0.5)\n",
        "        x = self.fc_2(x)\n",
        "        return x\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load the data\n",
        "\n",
        "raw_image = False\n",
        "(x_train, y_train), (x_test, y_test), min_, max_ = load_data(raw_image, 5000)\n",
        "# Create the model\n",
        "\n",
        "model_table1 = Net_table1_CIFAR10()\n",
        "\n",
        "# model_scratch = Net_table1_CIFAR10()\n",
        "# print(summary(model_scratch,(3, 32, 32)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5DkYgW8c-lD0",
        "outputId": "5464c170-9e2c-4354-ad42-374e7e92185e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32, 32, 3)\n",
            "change `raw_image` to be True for showing images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Ci0O2Tb8LUEE",
        "outputId": "ba02fa5e-fdba-4894-8bad-2b3fb3356113"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uKm-VeuuQO4l",
        "outputId": "23c275d0-2a23-46f0-ebd3-768016c77b9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No existing model, training the model instead\n",
            "art.estimators.classification.pytorch.PyTorchClassifier(model=ModelWrapper(\n",
            "  (_model): Net_table1_CIFAR10(\n",
            "    (conv_1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1))\n",
            "    (conv_2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
            "    (conv_3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
            "    (conv_4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
            "    (fc_1): Linear(in_features=3200, out_features=256, bias=True)\n",
            "    (fc_2): Linear(in_features=256, out_features=10, bias=True)\n",
            "  )\n",
            "), loss=CrossEntropyLoss(), optimizer=SGD (\n",
            "Parameter Group 0\n",
            "    dampening: 0\n",
            "    lr: 0.01\n",
            "    momentum: 0.9\n",
            "    nesterov: False\n",
            "    weight_decay: 0\n",
            "), input_shape=(3, 32, 32), nb_classes=10, channels_first=True, clip_values=array([0., 1.], dtype=float32), preprocessing_defences=None, postprocessing_defences=None, preprocessing=StandardisationMeanStdPyTorch(mean=0.0, std=1.0, apply_fit=True, apply_predict=True, device=cuda:0))\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from art.estimators.classification import PyTorchClassifier\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer_table1 = optim.SGD(model_table1.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "# Create the ART classifier\n",
        "\n",
        "classifier_table1 = PyTorchClassifier(\n",
        "    model=model_table1,\n",
        "    clip_values=(min_, max_),\n",
        "    loss=criterion,\n",
        "    optimizer=optimizer_table1,\n",
        "    input_shape=(3, 32, 32),\n",
        "    nb_classes=10,\n",
        "    device_type = \"gpu\",\n",
        ")\n",
        "\n",
        "# Swap axes to PyTorch's NCHW format\n",
        "x_train = np.transpose(x_train, (0, 3, 2, 1)).astype(np.float32)\n",
        "x_test = np.transpose(x_test, (0, 3, 2, 1)).astype(np.float32)\n",
        "\n",
        "ML_model_Filename = \"Pytorch_Model_CIFAR10_table1-0-1.pth\"\n",
        "path = F\"/content/gdrive/MyDrive/{ML_model_Filename}\"\n",
        "\n",
        "try:\n",
        "    with open(path, 'rb') as file:  \n",
        "        # classifier_table1 = pickle.load(file)\n",
        "        classifier_table1 = torch.load(file)\n",
        "except FileNotFoundError:\n",
        "    print('No existing model, training the model instead')\n",
        "    classifier_table1.fit(x_train, y_train, batch_size=128, nb_epochs=50)\n",
        "    # Save the model\n",
        "    with open(path, 'wb'):  \n",
        "        # pickle.dump(classifier_table1, file)\n",
        "        torch.save(classifier_table1, path)\n",
        "\n",
        "print(classifier_table1) "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "sign_opt_CIFAR10_test",
      "provenance": [],
      "history_visible": true,
      "authorship_tag": "ABX9TyPB+wztNdev+K+v+xDP7t1s",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}